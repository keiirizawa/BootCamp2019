{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree-based Methods\n",
    "### by [Richard W. Evans](https://sites.google.com/site/rickecon/), February 2019\n",
    "The code in this Jupyter notebook was written using Python 3.6. It uses data files `hitters.csv` and the iris dataset from scikit-learn. For the code to run properly, you will either need to have access to the internet or you should have the data file in the same folder as the Jupyter notebook file. Otherwise, you will have to change the respective lines of the code that read in the data to reflect the location of that data.\n",
    "\n",
    "This notebook follows some of the material in James, et al (2013, Ch. 8). Everything in this notebook will build to the methods of Random Forests and Boosting. But it is helpful to talk about the intermediate models to build up the intuitoin for the more complex models. We will cover:\n",
    "\n",
    "1. Basic decision trees\n",
    "2. Bagging\n",
    "3. Random Forests\n",
    "4. Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic decision trees\n",
    "The documentation for [`scikit-learn`'s decision tree libraries](http://scikit-learn.org/stable/modules/tree.html) states, \"Decision Trees (DTs) are a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.\" Figures 8.1 and 8.2 from James, et al (2013) shows a basic three-region, three-leaf, three partition decision tree for the `Hitters` data from the book used to predict a professional baseball player's salary. Each partition represents a terminal node of the tree, or a leaf. The points along the ree where the predictor space is split are referred to as internal nodes. The segments that connect the nodes are called branches.\n",
    "\n",
    "![Figure8_1.png](images/Figure8_1.png)\n",
    "\n",
    "![Figure8_2.png](images/Figure8_2.png)\n",
    "\n",
    "The three regions are $R_1 = \\{Y_i|Years_i<4.5\\}$, $R_2 = \\{Y_i|Years_i\\geq 4.5 \\: \\& \\: Hits_i<117.5\\}$, and $R_3 = \\{Y_i|Years_i\\geq 4.5 \\: \\& \\: Hits_i\\geq 117.5\\}$.\n",
    "\n",
    "More generally, to predict $Y$ using tree based methods:\n",
    "\n",
    "1. Choose how many $P$ predictors to use in the feature space $X_1, X_2,... X_P$,\n",
    "2. Divide the feature space into $J$ mutually exclusive regions $R_1, R_2,... R_J$,\n",
    "3. For $Y_i\\in R_j$, predict mean value $Y_i= \\frac{1}{N_j}\\sum_{k=1}^{N_j}Y_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Regression trees\n",
    "Regression trees are trees in which the predicted values at the leaves or terminal nodes are continuous variable values. The predicted salaries from the `Hitters` baseball wage data is the average salary in each region.\n",
    "\n",
    "* $R_1 = \\{X_i|Years_i<4.5\\} = \\$1,000 \\times e^{5.107} \\approx \\$165,174 $\n",
    "* $R_2 = \\{X_i|Years_i\\geq 4.5 \\: \\& \\: Hits_i<117.5\\} = \\$1,000 \\times e^{5.999} \\approx \\$402,834 $\n",
    "* $R_3 = \\{X_i|Years_i\\geq 4.5 \\: \\& \\: Hits_i\\geq 117.5\\} = \\$1,000 \\times e^{6.740} \\approx \\$845,346 $\n",
    "\n",
    "**Four key questions**\n",
    "1. How do we choose which feature variables to use?\n",
    "2. How do we choose the cutoffs or bifurcation points for each node (e.g., $Years_i<4.5$)?\n",
    "3. How do we choose which features or variables are at the base of the tree and which ones are at the ends of the branches?\n",
    "4. How do we measure accuracy and fit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the last question (4). The structure of a decision tree--feature variables, cutoffs, and order of appearance--is chosen to minimize the residual sum of squares $RSS$ of a training data set.\n",
    "\n",
    "$$ RSS = \\sum_{j=1}^J\\sum_{i\\in R_j}\\left(y_i - \\hat{y}_i\\right)^2 $$\n",
    "\n",
    "This is equivalent to minimizing the mean squared error $MSE$ of the training set. $MSE$ only differs from the $RSS$ or $SSE$ by a scalar $1/N_j$.\n",
    "\n",
    "$$ MSE = \\frac{1}{N_j}\\sum_{j=1}^J\\sum_{i\\in R_j}\\left(y_i - \\hat{y}_i\\right)^2 $$\n",
    "\n",
    "But, as with the linear regression methods and classification methods of earlier notebooks, the accuracy of the model is measured by the MSE and estimated error rate of the model on a test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer to question (1) is up to the modeler. The cutoff/bifurcation points (2) and the order in which the variables apear in the tree from the base to the leaves (3) are chosen to minimize the RSS. We can use *recursive binary splitting* to choose the cutoff or bifurcation points of each node.\n",
    "\n",
    "1. Solve for the predictor $X_j$ and cutoff\\bifurcation $t_j$ that gives the lowest RSS in the training set. Any $X_j$ and $t_j$ divides the space into two half-planes $R_1(j,t_j)=\\{X|X_j<t_j\\}$ and $R_2(j,t_j)=\\{X|X_j<t_j\\}$. We seek the variable $X_j$ and cutoff $t_j$ that minimmize the RSS. This must be done by solving for the optimal cutoff $t_j$ for each $X_j$.\n",
    "\n",
    "$$ (X_1, t_1) = (X_j, t_j): \\quad \\min_{(X_j, t_j)}\\sum_{x_i\\in R_1(j,t_j)}\\left(y_i -\\hat{y}_i\\right)^2 + \\sum_{x_i\\in R_2(j,t_j)}\\left(y_i -\\hat{y}_i\\right)^2 $$\n",
    "\n",
    "2. Solve for the best predictor on each branch of the previously optimized variable by cycling through each feature $X_j$ and solving for the one in each branch with the minimum RSS.\n",
    "\n",
    "3. Continue this process until a stopping criterion is reached (e.g., no region contains more than 5 observations.\n",
    "\n",
    "Figure 8.3 from James, et al (2013) shows a five-region example.\n",
    "\n",
    "![Figure8_3.png](images/Figure8_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each possible end of a branch of the tree is called a terminal node or a leaf.\n",
    "\n",
    "Tree is solved by recursive binary splitting.\n",
    "* Which variable gives the lowest mean squared error for an optimal binary split\n",
    "* On each branch of that binary split, which variable gives the lowest mean squared error for an optimal binary split\n",
    "* Repeat until \"some\" stoppping point\n",
    "\n",
    "You could imagine lots of possible trees based on different data. Furthermore, it is not true in general that this recursive binary splitting will give the best fit. For example, you might get the best fit by starting with a variable that does not provide the biggest reduction in MSE but does indicate other variables that provide a big reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AtBat   Hits  HmRun  Runs   RBI  Walks  Years  CAtBat   CHits  CHmRun  \\\n",
      "1  315.0   81.0    7.0  24.0  38.0   39.0   14.0  3449.0   835.0    69.0   \n",
      "2  479.0  130.0   18.0  66.0  72.0   76.0    3.0  1624.0   457.0    63.0   \n",
      "3  496.0  141.0   20.0  65.0  78.0   37.0   11.0  5628.0  1575.0   225.0   \n",
      "4  321.0   87.0   10.0  39.0  42.0   30.0    2.0   396.0   101.0    12.0   \n",
      "5  594.0  169.0    4.0  74.0  51.0   35.0   11.0  4408.0  1133.0    19.0   \n",
      "\n",
      "   CRuns   CRBI  CWalks  PutOuts  Assists  Errors  Salary  \n",
      "1  321.0  414.0   375.0    632.0     43.0    10.0   475.0  \n",
      "2  224.0  266.0   263.0    880.0     82.0    14.0   480.0  \n",
      "3  828.0  838.0   354.0    200.0     11.0     3.0   500.0  \n",
      "4   48.0   46.0    33.0    805.0     40.0     4.0    91.5  \n",
      "5  501.0  336.0   194.0    282.0    421.0    25.0   750.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 263 entries, 1 to 321\n",
      "Data columns (total 17 columns):\n",
      "AtBat      263 non-null float64\n",
      "Hits       263 non-null float64\n",
      "HmRun      263 non-null float64\n",
      "Runs       263 non-null float64\n",
      "RBI        263 non-null float64\n",
      "Walks      263 non-null float64\n",
      "Years      263 non-null float64\n",
      "CAtBat     263 non-null float64\n",
      "CHits      263 non-null float64\n",
      "CHmRun     263 non-null float64\n",
      "CRuns      263 non-null float64\n",
      "CRBI       263 non-null float64\n",
      "CWalks     263 non-null float64\n",
      "PutOuts    263 non-null float64\n",
      "Assists    263 non-null float64\n",
      "Errors     263 non-null float64\n",
      "Salary     263 non-null float64\n",
      "dtypes: float64(17)\n",
      "memory usage: 37.0 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Install the open source GraphViz program using\n",
    "# conda install python-graphviz\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "\n",
    "hitters = pd.read_csv('Hitters.csv', sep=',')\n",
    "# Drop observations with NaN in Salary\n",
    "hitters = hitters.dropna()\n",
    "print(hitters.head())\n",
    "y = hitters['Salary'].values\n",
    "X = hitters[['AtBat', 'Hits', 'HmRun', 'Runs', 'RBI', 'Walks',\n",
    "             'Years', 'CAtBat', 'CHits', 'CHmRun', 'CRuns',\n",
    "             'CRBI', 'CWalks', 'PutOuts', 'Assists', 'Errors']].values\n",
    "print(hitters.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the documentation for [sklearn.tree.DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html). Key tuning parameters are:\n",
    "* max_depth, min_samples_split, min_samples_leaf, max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=3, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=5,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_tree = DecisionTreeRegressor(max_depth=3, min_samples_leaf=5)\n",
    "hit_tree.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"704pt\" height=\"373pt\"\n",
       " viewBox=\"0.00 0.00 704.00 373.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 369)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-369 700,-369 700,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#f7d6bf\" stroke=\"#000000\" d=\"M270,-365C270,-365 190,-365 190,-365 184,-365 178,-359 178,-353 178,-353 178,-309 178,-309 178,-303 184,-297 190,-297 190,-297 270,-297 270,-297 276,-297 282,-303 282,-309 282,-309 282,-353 282,-353 282,-359 276,-365 270,-365\"/>\n",
       "<text text-anchor=\"middle\" x=\"230\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[8] &lt;= 450.0</text>\n",
       "<text text-anchor=\"middle\" x=\"230\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 202734.158</text>\n",
       "<text text-anchor=\"middle\" x=\"230\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 263</text>\n",
       "<text text-anchor=\"middle\" x=\"230\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 535.926</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#fdf6f1\" stroke=\"#000000\" d=\"M208,-261C208,-261 134,-261 134,-261 128,-261 122,-255 122,-249 122,-249 122,-205 122,-205 122,-199 128,-193 134,-193 134,-193 208,-193 208,-193 214,-193 220,-199 220,-205 220,-205 220,-249 220,-249 220,-255 214,-261 208,-261\"/>\n",
       "<text text-anchor=\"middle\" x=\"171\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[0] &lt;= 147.0</text>\n",
       "<text text-anchor=\"middle\" x=\"171\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 50693.014</text>\n",
       "<text text-anchor=\"middle\" x=\"171\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 117</text>\n",
       "<text text-anchor=\"middle\" x=\"171\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 227.855</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M210.6812,-296.9465C205.7913,-288.3271 200.4761,-278.9579 195.3722,-269.9611\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"198.3408,-268.1008 190.3622,-261.13 192.2524,-271.5549 198.3408,-268.1008\"/>\n",
       "<text text-anchor=\"middle\" x=\"183.7092\" y=\"-281.5285\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<path fill=\"#f1bd97\" stroke=\"#000000\" d=\"M386,-261C386,-261 306,-261 306,-261 300,-261 294,-255 294,-249 294,-249 294,-205 294,-205 294,-199 300,-193 306,-193 306,-193 386,-193 386,-193 392,-193 398,-199 398,-205 398,-205 398,-249 398,-249 398,-255 392,-261 386,-261\"/>\n",
       "<text text-anchor=\"middle\" x=\"346\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[5] &lt;= 61.0</text>\n",
       "<text text-anchor=\"middle\" x=\"346\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 187569.858</text>\n",
       "<text text-anchor=\"middle\" x=\"346\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 146</text>\n",
       "<text text-anchor=\"middle\" x=\"346\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 782.805</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>0&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M267.9827,-296.9465C278.2977,-287.6986 289.5754,-277.5876 300.2699,-267.9994\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"302.8226,-270.4115 307.9319,-261.13 298.1498,-265.1995 302.8226,-270.4115\"/>\n",
       "<text text-anchor=\"middle\" x=\"306.5703\" y=\"-282.3929\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#f3c4a3\" stroke=\"#000000\" d=\"M92,-149.5C92,-149.5 12,-149.5 12,-149.5 6,-149.5 0,-143.5 0,-137.5 0,-137.5 0,-108.5 0,-108.5 0,-102.5 6,-96.5 12,-96.5 12,-96.5 92,-96.5 92,-96.5 98,-96.5 104,-102.5 104,-108.5 104,-108.5 104,-137.5 104,-137.5 104,-143.5 98,-149.5 92,-149.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"52\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 588034.581</text>\n",
       "<text text-anchor=\"middle\" x=\"52\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 5</text>\n",
       "<text text-anchor=\"middle\" x=\"52\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 709.466</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M132.0349,-192.9465C118.5491,-181.1606 103.4591,-167.9726 90.0479,-156.2519\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"92.2033,-153.4874 82.3704,-149.5422 87.5969,-158.7582 92.2033,-153.4874\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#fef8f5\" stroke=\"#000000\" d=\"M208,-157C208,-157 134,-157 134,-157 128,-157 122,-151 122,-145 122,-145 122,-101 122,-101 122,-95 128,-89 134,-89 134,-89 208,-89 208,-89 214,-89 220,-95 220,-101 220,-101 220,-145 220,-145 220,-151 214,-157 208,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"171\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[11] &lt;= 114.5</text>\n",
       "<text text-anchor=\"middle\" x=\"171\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 15887.394</text>\n",
       "<text text-anchor=\"middle\" x=\"171\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 112</text>\n",
       "<text text-anchor=\"middle\" x=\"171\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 206.354</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M171,-192.9465C171,-184.776 171,-175.9318 171,-167.3697\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"174.5001,-167.13 171,-157.13 167.5001,-167.13 174.5001,-167.13\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#ffffff\" stroke=\"#000000\" d=\"M92,-53C92,-53 24,-53 24,-53 18,-53 12,-47 12,-41 12,-41 12,-12 12,-12 12,-6 18,0 24,0 24,0 92,0 92,0 98,0 104,-6 104,-12 104,-12 104,-41 104,-41 104,-47 98,-53 92,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"58\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 4082.728</text>\n",
       "<text text-anchor=\"middle\" x=\"58\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 74</text>\n",
       "<text text-anchor=\"middle\" x=\"58\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 141.759</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M131.1604,-88.9777C120.1161,-79.546 108.139,-69.3178 97.1352,-59.9208\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"99.1994,-57.081 89.3221,-53.2485 94.6536,-62.4041 99.1994,-57.081\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<path fill=\"#fbebe0\" stroke=\"#000000\" d=\"M208,-53C208,-53 134,-53 134,-53 128,-53 122,-47 122,-41 122,-41 122,-12 122,-12 122,-6 128,0 134,0 134,0 208,0 208,0 214,0 220,-6 220,-12 220,-12 220,-41 220,-41 220,-47 214,-53 208,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"171\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 14926.709</text>\n",
       "<text text-anchor=\"middle\" x=\"171\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 38</text>\n",
       "<text text-anchor=\"middle\" x=\"171\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 332.145</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>3&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M171,-88.9777C171,-80.7364 171,-71.887 171,-63.5153\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"174.5001,-63.2484 171,-53.2485 167.5001,-63.2485 174.5001,-63.2484\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<path fill=\"#f4cbad\" stroke=\"#000000\" d=\"M383,-157C383,-157 309,-157 309,-157 303,-157 297,-151 297,-145 297,-145 297,-101 297,-101 297,-95 303,-89 309,-89 309,-89 383,-89 383,-89 389,-89 395,-95 395,-101 395,-101 395,-145 395,-145 395,-151 389,-157 383,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"346\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[0] &lt;= 395.5</text>\n",
       "<text text-anchor=\"middle\" x=\"346\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 91056.703</text>\n",
       "<text text-anchor=\"middle\" x=\"346\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 104</text>\n",
       "<text text-anchor=\"middle\" x=\"346\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 649.623</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>6&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M346,-192.9465C346,-184.776 346,-175.9318 346,-167.3697\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"349.5001,-167.13 346,-157.13 342.5001,-167.13 349.5001,-167.13\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<path fill=\"#ea9b62\" stroke=\"#000000\" d=\"M562,-157C562,-157 482,-157 482,-157 476,-157 470,-151 470,-145 470,-145 470,-101 470,-101 470,-95 476,-89 482,-89 482,-89 562,-89 562,-89 568,-89 574,-95 574,-101 574,-101 574,-145 574,-145 574,-151 568,-157 562,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"522\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[4] &lt;= 73.5</text>\n",
       "<text text-anchor=\"middle\" x=\"522\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 273876.901</text>\n",
       "<text text-anchor=\"middle\" x=\"522\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 42</text>\n",
       "<text text-anchor=\"middle\" x=\"522\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 1112.588</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>6&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M398.3293,-196.0782C418.1009,-184.3949 440.7644,-171.0028 461.2439,-158.9013\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"463.0436,-161.9033 469.8723,-153.8027 459.4825,-155.8768 463.0436,-161.9033\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<path fill=\"#f7d9c3\" stroke=\"#000000\" d=\"M324,-53C324,-53 250,-53 250,-53 244,-53 238,-47 238,-41 238,-41 238,-12 238,-12 238,-6 244,0 250,0 250,0 324,0 324,0 330,0 336,-6 336,-12 336,-12 336,-41 336,-41 336,-47 330,-53 324,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"287\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 53952.267</text>\n",
       "<text text-anchor=\"middle\" x=\"287\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 53</text>\n",
       "<text text-anchor=\"middle\" x=\"287\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 510.016</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>7&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M325.1988,-88.9777C319.8242,-80.187 314.0265,-70.7044 308.6115,-61.8477\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"311.5564,-59.9545 303.354,-53.2485 305.5842,-63.6059 311.5564,-59.9545\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<path fill=\"#f1bc95\" stroke=\"#000000\" d=\"M440,-53C440,-53 366,-53 366,-53 360,-53 354,-47 354,-41 354,-41 354,-12 354,-12 354,-6 360,0 366,0 366,0 440,0 440,0 446,0 452,-6 452,-12 452,-12 452,-41 452,-41 452,-47 446,-53 440,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"403\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 88312.866</text>\n",
       "<text text-anchor=\"middle\" x=\"403\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 51</text>\n",
       "<text text-anchor=\"middle\" x=\"403\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 794.705</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>7&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M366.0961,-88.9777C371.2344,-80.2786 376.773,-70.9018 381.9575,-62.1247\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"385.1281,-63.6387 387.2004,-53.2485 379.101,-60.0786 385.1281,-63.6387\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<path fill=\"#efb286\" stroke=\"#000000\" d=\"M562,-53C562,-53 482,-53 482,-53 476,-53 470,-47 470,-41 470,-41 470,-12 470,-12 470,-6 476,0 482,0 482,0 562,0 562,0 568,0 574,-6 574,-12 574,-12 574,-41 574,-41 574,-47 568,-53 562,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"522\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 143099.113</text>\n",
       "<text text-anchor=\"middle\" x=\"522\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 22</text>\n",
       "<text text-anchor=\"middle\" x=\"522\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 885.265</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>10&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M522,-88.9777C522,-80.7364 522,-71.887 522,-63.5153\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"525.5001,-63.2484 522,-53.2485 518.5001,-63.2485 525.5001,-63.2484\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<path fill=\"#e58139\" stroke=\"#000000\" d=\"M684,-53C684,-53 604,-53 604,-53 598,-53 592,-47 592,-41 592,-41 592,-12 592,-12 592,-6 598,0 604,0 604,0 684,0 684,0 690,0 696,-6 696,-12 696,-12 696,-41 696,-41 696,-47 690,-53 684,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"644\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 298361.644</text>\n",
       "<text text-anchor=\"middle\" x=\"644\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 20</text>\n",
       "<text text-anchor=\"middle\" x=\"644\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 1362.643</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>10&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M565.0126,-88.9777C577.0524,-79.4545 590.1188,-69.1191 602.0935,-59.6473\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"604.5115,-62.1973 610.1833,-53.2485 600.1689,-56.7072 604.5115,-62.1973\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1a1d758898>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "hit_tree_viz = export_graphviz(\n",
    "    hit_tree,\n",
    "    out_file=None,\n",
    "    # feature_names=iris.feature_names[2:],\n",
    "    # class_names=iris.target_names,\n",
    "    rounded=True,\n",
    "    filled=True,\n",
    ")\n",
    "\n",
    "graph = graphviz.Source(hit_tree_viz)\n",
    "graph.render('hit_tree_viz')\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take the validation set approach to cross validation, break the data into training set and test set, and test the MSE of our predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=3, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=4,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .4,\n",
    "                                                    random_state=25)\n",
    "hit_tree2 = DecisionTreeRegressor(max_depth=3, min_samples_leaf=4)\n",
    "hit_tree2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"912pt\" height=\"373pt\"\n",
       " viewBox=\"0.00 0.00 912.00 373.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 369)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-369 908,-369 908,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#f9e2d2\" stroke=\"#000000\" d=\"M481,-365C481,-365 401,-365 401,-365 395,-365 389,-359 389,-353 389,-353 389,-309 389,-309 389,-303 395,-297 401,-297 401,-297 481,-297 481,-297 487,-297 493,-303 493,-309 493,-309 493,-353 493,-353 493,-359 487,-365 481,-365\"/>\n",
       "<text text-anchor=\"middle\" x=\"441\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[8] &lt;= 450.0</text>\n",
       "<text text-anchor=\"middle\" x=\"441\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 197520.384</text>\n",
       "<text text-anchor=\"middle\" x=\"441\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 157</text>\n",
       "<text text-anchor=\"middle\" x=\"441\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 542.608</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#fefaf7\" stroke=\"#000000\" d=\"M365,-261C365,-261 291,-261 291,-261 285,-261 279,-255 279,-249 279,-249 279,-205 279,-205 279,-199 285,-193 291,-193 291,-193 365,-193 365,-193 371,-193 377,-199 377,-205 377,-205 377,-249 377,-249 377,-255 371,-261 365,-261\"/>\n",
       "<text text-anchor=\"middle\" x=\"328\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[12] &lt;= 117.5</text>\n",
       "<text text-anchor=\"middle\" x=\"328\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 24898.312</text>\n",
       "<text text-anchor=\"middle\" x=\"328\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 71</text>\n",
       "<text text-anchor=\"middle\" x=\"328\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 218.465</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M403.9996,-296.9465C393.9514,-287.6986 382.9653,-277.5876 372.5474,-267.9994\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"374.8118,-265.3267 365.0836,-261.13 370.0714,-270.4773 374.8118,-265.3267\"/>\n",
       "<text text-anchor=\"middle\" x=\"366.1195\" y=\"-282.4085\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<path fill=\"#f5cfb3\" stroke=\"#000000\" d=\"M597,-261C597,-261 517,-261 517,-261 511,-261 505,-255 505,-249 505,-249 505,-205 505,-205 505,-199 511,-193 517,-193 517,-193 597,-193 597,-193 603,-193 609,-199 609,-205 609,-205 609,-249 609,-249 609,-255 603,-261 597,-261\"/>\n",
       "<text text-anchor=\"middle\" x=\"557\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[4] &lt;= 80.5</text>\n",
       "<text text-anchor=\"middle\" x=\"557\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 181677.336</text>\n",
       "<text text-anchor=\"middle\" x=\"557\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 86</text>\n",
       "<text text-anchor=\"middle\" x=\"557\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 810.215</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>0&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M478.9827,-296.9465C489.2977,-287.6986 500.5754,-277.5876 511.2699,-267.9994\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"513.8226,-270.4115 518.9319,-261.13 509.1498,-265.1995 513.8226,-270.4115\"/>\n",
       "<text text-anchor=\"middle\" x=\"517.5703\" y=\"-282.3929\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#fffefd\" stroke=\"#000000\" d=\"M196,-157C196,-157 128,-157 128,-157 122,-157 116,-151 116,-145 116,-145 116,-101 116,-101 116,-95 122,-89 128,-89 128,-89 196,-89 196,-89 202,-89 208,-95 208,-101 208,-101 208,-145 208,-145 208,-151 202,-157 196,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"162\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[13] &lt;= 595.0</text>\n",
       "<text text-anchor=\"middle\" x=\"162\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 15001.22</text>\n",
       "<text text-anchor=\"middle\" x=\"162\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 54</text>\n",
       "<text text-anchor=\"middle\" x=\"162\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 165.417</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M278.644,-196.0782C259.1632,-183.8733 236.7059,-169.8037 216.7298,-157.2886\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"218.3747,-154.1889 208.0422,-151.8457 214.6582,-160.1209 218.3747,-154.1889\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<path fill=\"#fbeee4\" stroke=\"#000000\" d=\"M365,-157C365,-157 291,-157 291,-157 285,-157 279,-151 279,-145 279,-145 279,-101 279,-101 279,-95 285,-89 291,-89 291,-89 365,-89 365,-89 371,-89 377,-95 377,-101 377,-101 377,-145 377,-145 377,-151 371,-157 365,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"328\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[0] &lt;= 358.0</text>\n",
       "<text text-anchor=\"middle\" x=\"328\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 19003.014</text>\n",
       "<text text-anchor=\"middle\" x=\"328\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 17</text>\n",
       "<text text-anchor=\"middle\" x=\"328\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 386.971</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>1&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M328,-192.9465C328,-184.776 328,-175.9318 328,-167.3697\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"331.5001,-167.13 328,-157.13 324.5001,-167.13 331.5001,-167.13\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#ffffff\" stroke=\"#000000\" d=\"M80,-53C80,-53 12,-53 12,-53 6,-53 0,-47 0,-41 0,-41 0,-12 0,-12 0,-6 6,0 12,0 12,0 80,0 80,0 86,0 92,-6 92,-12 92,-12 92,-41 92,-41 92,-47 86,-53 80,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"46\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 4397.046</text>\n",
       "<text text-anchor=\"middle\" x=\"46\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 50</text>\n",
       "<text text-anchor=\"middle\" x=\"46\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 150.12</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M121.1027,-88.9777C109.6551,-79.4545 97.2313,-69.1191 85.8455,-59.6473\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"88.0797,-56.9532 78.1536,-53.2485 83.6029,-62.3345 88.0797,-56.9532\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#fcf0e7\" stroke=\"#000000\" d=\"M202,-53C202,-53 122,-53 122,-53 116,-53 110,-47 110,-41 110,-41 110,-12 110,-12 110,-6 116,0 122,0 122,0 202,0 202,0 208,0 214,-6 214,-12 214,-12 214,-41 214,-41 214,-47 208,-53 202,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"162\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 108067.922</text>\n",
       "<text text-anchor=\"middle\" x=\"162\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4</text>\n",
       "<text text-anchor=\"middle\" x=\"162\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 356.625</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M162,-88.9777C162,-80.7364 162,-71.887 162,-63.5153\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"165.5001,-63.2484 162,-53.2485 158.5001,-63.2485 165.5001,-63.2484\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<path fill=\"#fdf6f0\" stroke=\"#000000\" d=\"M306,-53C306,-53 244,-53 244,-53 238,-53 232,-47 232,-41 232,-41 232,-12 232,-12 232,-6 238,0 244,0 244,0 306,0 306,0 312,0 318,-6 318,-12 318,-12 318,-41 318,-41 318,-47 312,-53 306,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"275\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 1928.76</text>\n",
       "<text text-anchor=\"middle\" x=\"275\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 5</text>\n",
       "<text text-anchor=\"middle\" x=\"275\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 278.7</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M309.3142,-88.9777C304.5364,-80.2786 299.3865,-70.9018 294.5659,-62.1247\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"297.5726,-60.3286 289.6909,-53.2485 291.4371,-63.6984 297.5726,-60.3286\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<path fill=\"#fbeadf\" stroke=\"#000000\" d=\"M422,-53C422,-53 348,-53 348,-53 342,-53 336,-47 336,-41 336,-41 336,-12 336,-12 336,-6 342,0 348,0 348,0 422,0 422,0 428,0 434,-6 434,-12 434,-12 434,-41 434,-41 434,-47 428,-53 422,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"385\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 19197.743</text>\n",
       "<text text-anchor=\"middle\" x=\"385\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 12</text>\n",
       "<text text-anchor=\"middle\" x=\"385\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 432.083</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>5&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M348.0961,-88.9777C353.2344,-80.2786 358.773,-70.9018 363.9575,-62.1247\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"367.1281,-63.6387 369.2004,-53.2485 361.101,-60.0786 367.1281,-63.6387\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<path fill=\"#f7d8c1\" stroke=\"#000000\" d=\"M594,-157C594,-157 520,-157 520,-157 514,-157 508,-151 508,-145 508,-145 508,-101 508,-101 508,-95 514,-89 520,-89 520,-89 594,-89 594,-89 600,-89 606,-95 606,-101 606,-101 606,-145 606,-145 606,-151 600,-157 594,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"557\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[0] &lt;= 365.0</text>\n",
       "<text text-anchor=\"middle\" x=\"557\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 83475.624</text>\n",
       "<text text-anchor=\"middle\" x=\"557\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 67</text>\n",
       "<text text-anchor=\"middle\" x=\"557\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 690.206</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>8&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M557,-192.9465C557,-184.776 557,-175.9318 557,-167.3697\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"560.5001,-167.13 557,-157.13 553.5001,-167.13 560.5001,-167.13\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<path fill=\"#efb083\" stroke=\"#000000\" d=\"M773,-157C773,-157 693,-157 693,-157 687,-157 681,-151 681,-145 681,-145 681,-101 681,-101 681,-95 687,-89 693,-89 693,-89 773,-89 773,-89 779,-89 785,-95 785,-101 785,-101 785,-145 785,-145 785,-151 779,-157 773,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"733\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[4] &lt;= 84.5</text>\n",
       "<text text-anchor=\"middle\" x=\"733\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 298089.087</text>\n",
       "<text text-anchor=\"middle\" x=\"733\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 19</text>\n",
       "<text text-anchor=\"middle\" x=\"733\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 1233.407</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>8&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M609.3293,-196.0782C629.1009,-184.3949 651.7644,-171.0028 672.2439,-158.9013\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"674.0436,-161.9033 680.8723,-153.8027 670.4825,-155.8768 674.0436,-161.9033\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<path fill=\"#f9e3d3\" stroke=\"#000000\" d=\"M538,-53C538,-53 464,-53 464,-53 458,-53 452,-47 452,-41 452,-41 452,-12 452,-12 452,-6 458,0 464,0 464,0 538,0 538,0 544,0 550,-6 550,-12 550,-12 550,-41 550,-41 550,-47 544,-53 538,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"501\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 65984.355</text>\n",
       "<text text-anchor=\"middle\" x=\"501\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 27</text>\n",
       "<text text-anchor=\"middle\" x=\"501\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 531.79</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>9&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M537.2565,-88.9777C532.2083,-80.2786 526.7669,-70.9018 521.6734,-62.1247\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"524.5689,-60.1409 516.5224,-53.2485 518.5145,-63.6544 524.5689,-60.1409\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<path fill=\"#f5d0b5\" stroke=\"#000000\" d=\"M654,-53C654,-53 580,-53 580,-53 574,-53 568,-47 568,-41 568,-41 568,-12 568,-12 568,-6 574,0 580,0 580,0 654,0 654,0 660,0 666,-6 666,-12 666,-12 666,-41 666,-41 666,-47 660,-53 654,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"617\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 66908.549</text>\n",
       "<text text-anchor=\"middle\" x=\"617\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 40</text>\n",
       "<text text-anchor=\"middle\" x=\"617\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 797.136</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>9&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M578.1538,-88.9777C583.6195,-80.187 589.5154,-70.7044 595.0222,-61.8477\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"598.0609,-63.5889 600.3688,-53.2485 592.1163,-59.8927 598.0609,-63.5889\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<path fill=\"#e58139\" stroke=\"#000000\" d=\"M770,-53C770,-53 696,-53 696,-53 690,-53 684,-47 684,-41 684,-41 684,-12 684,-12 684,-6 690,0 696,0 696,0 770,0 770,0 776,0 782,-6 782,-12 782,-12 782,-41 782,-41 782,-47 776,-53 770,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"733\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 156018.75</text>\n",
       "<text text-anchor=\"middle\" x=\"733\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4</text>\n",
       "<text text-anchor=\"middle\" x=\"733\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 1877.5</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>12&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M733,-88.9777C733,-80.7364 733,-71.887 733,-63.5153\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"736.5001,-63.2484 733,-53.2485 729.5001,-63.2485 736.5001,-63.2484\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>14</title>\n",
       "<path fill=\"#f1bd97\" stroke=\"#000000\" d=\"M892,-53C892,-53 812,-53 812,-53 806,-53 800,-47 800,-41 800,-41 800,-12 800,-12 800,-6 806,0 812,0 812,0 892,0 892,0 898,0 904,-6 904,-12 904,-12 904,-41 904,-41 904,-47 898,-53 892,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"852\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 195845.602</text>\n",
       "<text text-anchor=\"middle\" x=\"852\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 15</text>\n",
       "<text text-anchor=\"middle\" x=\"852\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 1061.649</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>12&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M774.9549,-88.9777C786.6986,-79.4545 799.4438,-69.1191 811.124,-59.6473\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"813.4522,-62.2656 819.0148,-53.2485 809.0432,-56.8286 813.4522,-62.2656\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x117b11358>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_tree_viz2 = export_graphviz(\n",
    "    hit_tree2,\n",
    "    out_file=None,\n",
    "    # feature_names=iris.feature_names[2:],\n",
    "    # class_names=iris.target_names,\n",
    "    rounded=True,\n",
    "    filled=True,\n",
    ")\n",
    "\n",
    "graph = graphviz.Source(hit_tree_viz2)\n",
    "graph.render('hit_tree_viz2')\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE= 146493.11004907076\n"
     ]
    }
   ],
   "source": [
    "y_pred = hit_tree2.predict(X_test)\n",
    "MSE1 = mean_squared_error(y_test, y_pred)\n",
    "print('MSE=', MSE1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Tree pruning\n",
    "Recursive binary splitting provides the best fit on the training set, but is likely to overfit the data and perform poorly in terms of prediction and error rate on a test set. Analogous to what we saw in the classification and regression examples, a smaller tree might predict better on a test set. Furthermore, the number of samples in a terminal node or leaf should be greater than 1.\n",
    "\n",
    "Similar to adjusted $R$-squared and similar to lasso regression, we can use a tuning parameter $\\alpha\\in[0,1]$ that limits the number of branches on each tree by including a penalty to the RSS fit criterion that penalizes $|T|$ the number of terminal nodes on tree $T$. For each value of $\\alpha$ there corresponds an optimal subtree $T\\subset T_0$ such that:\n",
    "\n",
    "$$ \\sum_{m=1}^{|T|}\\sum_{X_i\\in R_m} \\left(y_i - \\hat{y}_i\\right)^2 + \\alpha|T| $$\n",
    "\n",
    "1. Use recursive binary splitting to grow a large tree on the training data, stopping only when each terminal node has fewer than some minimum number of observations.\n",
    "2. Apply cost complexity pruning to the large tree in order to obtain a sequence of best subtrees, as a function of $\\alpha$.\n",
    "3. Use $K$-fold cross validation ot choose $\\alpha$.\n",
    "4. Return the subtree from Step 2 that corresponds to the chose value of $\\alpha$\n",
    "\n",
    "This pruning currently must be coded by hand in Python. That is, `scikit-learn` does not have automatic pruning mechanisms. However, the justification is that effective pruning can be done by manipulating the parameters `max_depth`, `min_impurity_split`, `min_samples_leaf` and `min_samples_split`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Classification trees\n",
    "A classification tree is a decision tree that has a categorical variable as the outcome variables. For a classification tree, we predict that each observation belongs to the most commonly occurring class of training observations in the region to which it belongs. The classification error rate is simply the fraction of training observations in that region that do not belong to the most common class.\n",
    "\n",
    "$$ ErrorRate = 1 - \\max_{k}\\left(\\hat{p}_{m,k}\\right) $$\n",
    "\n",
    "However, classification error rate is not sensitive enough for growing trees. That is, it does not change for small changes in cutoff. For this reason, classification tree building uses either the *Gini index* or the *Entropy index* instead of the error rate.\n",
    "\n",
    "$$ Gini = \\sum_{k=1}^K \\hat{p}_{m,k}\\left(1 - \\hat{p}_{mk}\\right) $$\n",
    "\n",
    "$$ Entropy = -\\sum_{k=1}^K \\hat{p}_{m,k}\\ln\\left(\\hat{p}_{mk}\\right) $$\n",
    "\n",
    "Both the Gini index and the entropy are measures of node purity. They have values close to 0 if most of the samples in the node are in a single class (low variance) and they will both take on higher values closer to 1 if the samples in the node are in many different classes (high variance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, 2:] # petal length and width\n",
    "y = iris.target\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2)\n",
    "tree_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"289pt\" height=\"314pt\"\n",
       " viewBox=\"0.00 0.00 289.00 314.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 310)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-310 285,-310 285,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#ffffff\" stroke=\"#000000\" d=\"M166.5,-306C166.5,-306 57.5,-306 57.5,-306 51.5,-306 45.5,-300 45.5,-294 45.5,-294 45.5,-235 45.5,-235 45.5,-229 51.5,-223 57.5,-223 57.5,-223 166.5,-223 166.5,-223 172.5,-223 178.5,-229 178.5,-235 178.5,-235 178.5,-294 178.5,-294 178.5,-300 172.5,-306 166.5,-306\"/>\n",
       "<text text-anchor=\"middle\" x=\"112\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">petal length (cm) &lt;= 2.45</text>\n",
       "<text text-anchor=\"middle\" x=\"112\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.667</text>\n",
       "<text text-anchor=\"middle\" x=\"112\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 150</text>\n",
       "<text text-anchor=\"middle\" x=\"112\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [50, 50, 50]</text>\n",
       "<text text-anchor=\"middle\" x=\"112\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = setosa</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#e58139\" stroke=\"#000000\" d=\"M82,-179.5C82,-179.5 12,-179.5 12,-179.5 6,-179.5 0,-173.5 0,-167.5 0,-167.5 0,-123.5 0,-123.5 0,-117.5 6,-111.5 12,-111.5 12,-111.5 82,-111.5 82,-111.5 88,-111.5 94,-117.5 94,-123.5 94,-123.5 94,-167.5 94,-167.5 94,-173.5 88,-179.5 82,-179.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 50</text>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [50, 0, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = setosa</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M89.2662,-222.8796C83.2599,-211.8835 76.763,-199.9893 70.7067,-188.9015\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"73.6088,-186.9133 65.7435,-179.8149 67.4655,-190.2689 73.6088,-186.9133\"/>\n",
       "<text text-anchor=\"middle\" x=\"58.7034\" y=\"-200.1032\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#ffffff\" stroke=\"#000000\" d=\"M229.5,-187C229.5,-187 124.5,-187 124.5,-187 118.5,-187 112.5,-181 112.5,-175 112.5,-175 112.5,-116 112.5,-116 112.5,-110 118.5,-104 124.5,-104 124.5,-104 229.5,-104 229.5,-104 235.5,-104 241.5,-110 241.5,-116 241.5,-116 241.5,-175 241.5,-175 241.5,-181 235.5,-187 229.5,-187\"/>\n",
       "<text text-anchor=\"middle\" x=\"177\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">petal width (cm) &lt;= 1.75</text>\n",
       "<text text-anchor=\"middle\" x=\"177\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"177\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 100</text>\n",
       "<text text-anchor=\"middle\" x=\"177\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 50, 50]</text>\n",
       "<text text-anchor=\"middle\" x=\"177\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M134.7338,-222.8796C139.4565,-214.2335 144.4824,-205.0322 149.359,-196.1042\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"152.447,-197.752 154.1691,-187.2981 146.3037,-194.3964 152.447,-197.752\"/>\n",
       "<text text-anchor=\"middle\" x=\"161.2092\" y=\"-207.5864\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#4de88e\" stroke=\"#000000\" d=\"M156.5,-68C156.5,-68 83.5,-68 83.5,-68 77.5,-68 71.5,-62 71.5,-56 71.5,-56 71.5,-12 71.5,-12 71.5,-6 77.5,0 83.5,0 83.5,0 156.5,0 156.5,0 162.5,0 168.5,-6 168.5,-12 168.5,-12 168.5,-56 168.5,-56 168.5,-62 162.5,-68 156.5,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"120\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.168</text>\n",
       "<text text-anchor=\"middle\" x=\"120\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 54</text>\n",
       "<text text-anchor=\"middle\" x=\"120\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 49, 5]</text>\n",
       "<text text-anchor=\"middle\" x=\"120\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M155.7753,-103.9815C151.3119,-95.2504 146.5933,-86.0202 142.0987,-77.2281\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"145.1842,-75.5745 137.516,-68.2637 138.9514,-78.7608 145.1842,-75.5745\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#843de6\" stroke=\"#000000\" d=\"M269,-68C269,-68 199,-68 199,-68 193,-68 187,-62 187,-56 187,-56 187,-12 187,-12 187,-6 193,0 199,0 199,0 269,0 269,0 275,0 281,-6 281,-12 281,-12 281,-56 281,-56 281,-62 275,-68 269,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"234\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.043</text>\n",
       "<text text-anchor=\"middle\" x=\"234\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 46</text>\n",
       "<text text-anchor=\"middle\" x=\"234\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 1, 45]</text>\n",
       "<text text-anchor=\"middle\" x=\"234\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M198.2247,-103.9815C202.6881,-95.2504 207.4067,-86.0202 211.9013,-77.2281\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"215.0486,-78.7608 216.484,-68.2637 208.8158,-75.5745 215.0486,-78.7608\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1a1d850128>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "iris_tree = export_graphviz(\n",
    "    tree_clf,\n",
    "    out_file=None,\n",
    "    feature_names=iris.feature_names[2:],\n",
    "    class_names=iris.target_names,\n",
    "    rounded=True,\n",
    "    filled=True,\n",
    ")\n",
    "\n",
    "graph = graphviz.Source(iris_tree)\n",
    "graph.render('iris')\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Tuning Hyperparameters (model selection)\n",
    "In Section 1.1, we fit a number of decision tree regression models to predict $log(salary)$ using the 16 features in the data. We saw that there were some key parameters of the prediction model that influenced the model's accuracy on a test data set. In particular for the `scikit-learn.tree.DecisionTreeRegressor` model, the parameters `max_depth`, `min_samples_split`, and `min_samples_leaf` are hyperparameters that influence model prediction accuracy.\n",
    "\n",
    "Scikit Learn has built-in methods to evaluate machine learning models and optimize them across the many different combinations of hyperparameter values. The scikit-learn documentation Section 3.2 \"[Tuning the hyperparameters of an estimator](https://scikit-learn.org/stable/modules/grid_search.html)\" is a great reference for the different methods used for hyperparameter optimization. The particular method we will focus on in this notebook is [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV). This method takes random permutations of the hyperparameters and chooses the permutation that has the best fit. Another good method is [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV), which performs and exhaustive grid search of all possible permutations of specified hyperparameter values. This can be more computationally intensive than `RandomSearchCV`.\n",
    "\n",
    "Let's optimize our hyperparameter values in the hitters problem above using `RandomSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandBestEstimator1= DecisionTreeRegressor(criterion='mse', max_depth=9, max_features=None,\n",
      "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
      "                      presort=False, random_state=None, splitter='best')\n",
      "RandBestParams1= {'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 4}\n",
      "RandBestScore1= 0.05055555555555556\n",
      "GridBestEstimator1= DecisionTreeRegressor(criterion='mse', max_depth=4, max_features=None,\n",
      "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=3, min_weight_fraction_leaf=0.0,\n",
      "                      presort=False, random_state=None, splitter='best')\n",
      "GridBestParams1= {'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 3}\n",
      "GridBestScore1= 0.04833333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist1 = {'max_depth': sp_randint(2, 13),\n",
    "               'min_samples_split': sp_randint(2, 15),\n",
    "               'min_samples_leaf': sp_randint(1, 15)}\n",
    "\n",
    "param_grid1 = {'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13],\n",
    "               'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "               'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}\n",
    "\n",
    "hittree3 = DecisionTreeRegressor()\n",
    "\n",
    "# Run randomized hyperparameter search\n",
    "random_search1 = \\\n",
    "    RandomizedSearchCV(hittree3, param_distributions=param_dist1,\n",
    "                       n_iter=500, n_jobs=-1, cv=5, random_state=25,\n",
    "                       scoring='neg_mean_squared_error')\n",
    "\n",
    "# Run grid search hyperparameter search\n",
    "grid_search1 = \\\n",
    "    GridSearchCV(hittree3, param_grid=param_grid1,\n",
    "                       n_jobs=-1, cv=5,\n",
    "                       scoring='neg_mean_squared_error')\n",
    "\n",
    "random_search1.fit(X, y)\n",
    "print('RandBestEstimator1=', random_search1.best_estimator_)\n",
    "print('RandBestParams1=', random_search1.best_params_)\n",
    "print('RandBestScore1=', -random_search1.best_score_)\n",
    "\n",
    "grid_search1.fit(X, y)\n",
    "print('GridBestEstimator1=', grid_search1.best_estimator_)\n",
    "print('GridBestParams1=', grid_search1.best_params_)\n",
    "print('GridBestScore1=', -grid_search1.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bagging (Bootstrapping)\n",
    "Decision trees constructed by recursive binary splitting are sensitive to the training set on which they are estimated. That is, if you build one tree on a random sample from a dataset, and you build another tree from a different random sample from the same dataset, both trees will likely look significantly different from each other. Bootstrapping or bagging is a general-purpose procedure for reducing the variance of any statistical learning method. It works very well with decision trees.\n",
    "\n",
    "Bagging (or bootstrapping) is to take a large number $B$ of randomly drawn training sets from a dataset. Estimate a decision tree on each of those training sets $\\hat{f}^{*b}(x)$. Then let the bagging decision tree prediction $\\hat{f}_{bag}(x)$ be the average predicted value of $x$ across all the bootstrap sample trees.\n",
    "\n",
    "$$ \\hat{f}_{bag}(x) = \\frac{1}{B}\\sum_{b=1}^B \\hat{f}^{*b}(x) $$\n",
    "\n",
    "Bagging both reduces variance of the tree and increases predictive accuracy.\n",
    "\n",
    "The bagging tree equation above must be adjusted if the dependent variable that we are trying to predict is categorical. A common way to aggregate predictions across bootstrapped training samples is to use a majority vote rule. The predicted value is the one that has the highest share of predicted values across the space.\n",
    "\n",
    "![Figure8_8.png](images/Figure8_8.png)\n",
    "\n",
    "Figure 8.8 from James, et al (2013) shows the results on the error rate from using a bagging approach on some `Heart` data. The number of bootstrapped samples $B$ is shown on the $x$-axis. The number of random samples need only be as big as necessary to get the error rate to settle down, which in this case is around $B=130$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `scikit-learn`, there is a [`BaggingRegressor()`](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html) function for regression trees and a [`BaggingClassifier()`](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html) function for classification trees. These methods are called \"ensemble\" methods because they average an \"ensemble\" or collection of trees. Ensemble methods are a theme in predictive models and machine learning.\n",
    "\n",
    "Let's do a bagging version of our `max_depth=3` regression tree with the baseball salary data. Let's see if we can get the error rate down from $MSE=121264$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 263 entries, 1 to 321\n",
      "Data columns (total 17 columns):\n",
      "AtBat      263 non-null float64\n",
      "Hits       263 non-null float64\n",
      "HmRun      263 non-null float64\n",
      "Runs       263 non-null float64\n",
      "RBI        263 non-null float64\n",
      "Walks      263 non-null float64\n",
      "Years      263 non-null float64\n",
      "CAtBat     263 non-null float64\n",
      "CHits      263 non-null float64\n",
      "CHmRun     263 non-null float64\n",
      "CRuns      263 non-null float64\n",
      "CRBI       263 non-null float64\n",
      "CWalks     263 non-null float64\n",
      "PutOuts    263 non-null float64\n",
      "Assists    263 non-null float64\n",
      "Errors     263 non-null float64\n",
      "Salary     263 non-null float64\n",
      "dtypes: float64(17)\n",
      "memory usage: 37.0 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "y = hitters['Salary'].values\n",
    "X = hitters[['AtBat', 'Hits', 'HmRun', 'Runs', 'RBI', 'Walks',\n",
    "             'Years', 'CAtBat', 'CHits', 'CHmRun', 'CRuns',\n",
    "             'CRBI', 'CWalks', 'PutOuts', 'Assists', 'Errors']].values\n",
    "print(hitters.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE= 81795.88573736997\n"
     ]
    }
   ],
   "source": [
    "# n_estimators is how many samples from the data to take (the number of trees)\n",
    "# max_samples is the maximum number of observations to include in each bootstrapped data sample\n",
    "hit_tree3 = BaggingRegressor(DecisionTreeRegressor(), n_estimators=53,\n",
    "                             max_samples=100, bootstrap=True, oob_score=True, random_state=25)\n",
    "hit_tree3.fit(X, y)\n",
    "\n",
    "y_pred3 = hit_tree3.oob_prediction_\n",
    "MSE3 = mean_squared_error(y, y_pred3)\n",
    "print('MSE=', MSE3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the MSE of the bagging ensemble method as a function of the number of trees in order to estimate the optimal number of samples that gives the highest predictive accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/bagging.py:1011: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/bagging.py:1011: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/bagging.py:1011: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/bagging.py:1011: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/bagging.py:1011: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/bagging.py:1011: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min. MSE= 78683.17842347568 , Min. B= 53\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 10, 8\n",
    "sb.set_style('whitegrid')\n",
    "\n",
    "MSE_base = MSE1\n",
    "max_samples = 100\n",
    "MSE_vec = np.zeros(max_samples)\n",
    "for ind in range(1, max_samples + 1):\n",
    "    hit_tree_loop = BaggingRegressor(DecisionTreeRegressor(), n_estimators=ind,\n",
    "                                 max_samples=100, bootstrap=True, oob_score=True,\n",
    "                                 random_state=15)\n",
    "    hit_tree_loop.fit(X, y)\n",
    "    y_pred_loop = hit_tree_loop.oob_prediction_\n",
    "    MSE_vec[ind - 1] = mean_squared_error(y, y_pred_loop)\n",
    "    # print('MSE=', MSE_vec[ind - 1])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(np.arange(1, max_samples + 1), MSE_base * np.ones(max_samples),\n",
    "         label='Base MSE')\n",
    "plt.plot(np.arange(1, max_samples + 1), MSE_vec, label='Bagging MSE')\n",
    "# for the minor ticks, use no labels; default NullFormatter\n",
    "plt.title('Bagging MSE vs. Basic Tree MSE', fontsize=20)\n",
    "plt.xlabel(r'Max. bagging samples $B$')\n",
    "plt.ylabel(r'MSE')\n",
    "plt.xlim((0, max_samples + 1))\n",
    "plt.legend(loc='best')\n",
    "\n",
    "print('Min. MSE=', MSE_vec.min(), ', Min. B=', np.argwhere(MSE_vec == MSE_vec.min())[0, 0] - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean MSE= 80906.98626992443 , standard error= 952.790216699083\n"
     ]
    }
   ],
   "source": [
    "MSE_hat = MSE_vec[52:].mean()\n",
    "MSE_std = MSE_vec[52:].std()\n",
    "print('mean MSE=', MSE_hat, ', standard error=', MSE_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You probably noticed that we used some options that included the acronym OOB. With bagging (bootstrapped training samples), \"one can show that, on average, each bagged tree makes use of around two-thirds of the observations. The remaining one-third are referred to as *out of bag* (OOB) observations.\" OOB error rate estimation is to use all the trees in the ensemble to predict the out of bag observations. This results in approximately $B/3$ predictions for each observation. The predicted value is then the average of all the predictions.\n",
    "\n",
    "It can be shown that with $B$ sufficiently large, OOB error rate approaches the leave-one-out cross-validation (LOOCV) error rate. OOB is faster and more efficient than the method of averaging error rates for each random sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random Forests\n",
    "Bagging solves the problem of sensitivity of the estimated trees to the sample drawn for the training set by taking many samples and averaging the predictions. However, bagging does not solve the issue that the trees' structure in each sample will be correlated due to the trees using the same group of features in each sample. Random forest decision trees add one more layer of randomization that reduces the correlation in the trees that comes from a constant feature set.\n",
    "\n",
    "A random forest continues the bagging (bootstrapping) approach, but causes each tree from a sample of observations to have a randomly determined subset of features. In other words, each tree can only use a small subset of features. The intuition is the following. Randomizing the features allows us to better explore the full set of possible predictors. A typical number of features $m$ to limit each tree to use is $m=\\sqrt{P}$. This may require more bootstrapped (bagging) draws, but random forests have been shown to have better predictive accuracy than bagging alone.\n",
    "\n",
    "`Scikit-learn` also has functions to execute random forests. [`RandomForestRegressor()`](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) estimates a random forest decision tree regression model, and [`RandomForestClassifier()`](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) estimates a random forest decision tree classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB score= 0.9478338447824203\n",
      "MSE= 80046.73280409168\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "B4 =100\n",
    "m4 = 4\n",
    "hit_tree4 = RandomForestRegressor(n_estimators=B4, max_features=m4, bootstrap=True,\n",
    "                                  n_jobs=-1, oob_score=True, random_state=25)\n",
    "hit_tree4.fit(X, y)\n",
    "\n",
    "print('OOB score=', hit_tree4.score(X, y))\n",
    "y_pred4 = hit_tree4.oob_prediction_\n",
    "MSE4 = mean_squared_error(y, y_pred4)\n",
    "print('MSE=', MSE4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the baseline MSE, versus the bagging MSE, versus the random forest MSE as a function of the number of random draw training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min. bag MSE= 78683.17842347568 , Min. bag B= 53\n",
      "Min. rnd MSE= 75037.00760916114 , Min. rnd B= 48\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaoAAAEeCAYAAADb1FGVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xd4FNX6wPHvbrIpkJCQEDoIAr5iQRQUUQRU7IgFBSzYfoJysSDqBRUFe7vqtSAqKnZEEb0KotiQooIiWOMBsdBBQgkhPbu/P85sstlsypK2kPfzPHl2M3t29uzZmXnnlDnj8vl8KKWUUpHKXd8ZUEoppSqigUoppVRE00CllFIqommgUkopFdE0UCmllIpoGqiUUkpFtOj6zkAoIjIJmBjipV3AamA68JgxpqAO8uIDfjDGdK/tz6ptIjIf6Be02AdsB34AJhtj3qnrfFXFvvQ7hEtELgOmlfNyHpABLAUeNMZ8U1f5CkVExgCPAZcbY16qz7wEEpEOwJ9VSPq4MWZMLWen2kQkCRhujHmqknQdKPneq40xnStIewSwzPn3TmPMpKDXBwEjgaOAJGAbdrt7wRjzfgWfW5njjTHzK0oQkYEqwP+AFc7zKGzhHAc8CPQGzqmDPNwJbKqDz6lLjwM7nOcxQDPgdGCmiIwxxjxebzkr3774O4TrS2B+0LJkoBdwNjBQRI43xiyq64ztRf4GXqrg9XoN9GFYCWwEKgxUQTqJSDdjzI/lvH5eeW8UkSeBa4C/sMflrUAb4AxgkIhMNcaMDPHWysobZ50VivRA9V7wWZmIuID3gbNF5ARjzOe1mYHgs4p9xH+NMX8FLhCRZOAn4B4RmWaMyayXnJVjH/0dwjW/vHIQkbuA24GHgGPqMlN7mb/2kW2pOTZQVdUmoCVwLlBeoBoMZAEJgQtFpD82SL0DDDPGFAa8lgR8AYwQkTnGmP8FrbNGynuv66MyxvgoaQYJbsZSe8gYswN4F7uR9qjn7Kjw3QMUAL1FpFF9Z0ZFnKXABspphRKRbsABwAchXh7oPD4VGKQAjDE7gfHOv+fWTFbLivQaVXn8hZUXuFBEPMC/gAuArkA89qxjLnC7MeafgLSdgfuwzSYtnXQfAncZYzYFpCvTN+IcCMYBQ4H2wGbnvZMCPyNE3jY6eW7rBNzA158BrgJ6GWOWVjV/Nay8cm2G/b4Dgf2cxX8CrwMPBZ1hRQM3A5cD7Zx0/wFaA3cDHQNrcyJyFfZsrRP2rO8Z5/FlAtqug3+HgH7MrsAlwMVAC+B34EljzDNB3yEBW+MY6qT7FZgEnAX8nzHGVV6hiMj7wJnAgcYYE/TaMGyf6ThjzEPO59wNnAZ0ADKBRcA9xpjvy/uM6jLG5IvITmwzbgyQ7eQvnH3Chy3357DbXk9s8JvnfL+/Aj9TRM7CHqS6YfsrngFyQ+VPRA4A7gBOApoCa7Fn6Pc6Bzt/upco+S0fwDZpxgFfOd9jHXAXMBx7UrUMGGOM+SGsAqsiERkKXAd0x/bn/gg8YYx5MyBNB+x2fje2Kfb/gBxglDHmbacV6Cps/05XbBktBCYaY5YHfd7J2H3tUCARuz2/ATzi/Mb9sTUYgMOc36xMf1IIPuyJ6GgR6WSMWR30+nlOnudgt5VAHufxUMo2PeN8lyHAqkrysMf2uhqV86NfBhQB7wW9PB34L3bneg54FrtRXIU9yPvXkQZ8hm1fnQ88CvwCjAK+cHbu8j6/EbAYu9NlYnfOH7E70ecikhjqfc7Aj7ewB+w+QeuMxla7VzlBao/zt6ecKvy52API0qDlS4Ax2IP749gdpxVwL/ZgEugt7EEuB3ga25b+AjZwBX/mY9jyiwemAl876ww1kKY8rwEjsL/vVGy7+RQRGRHwOTHAp8C/gfXYdv2d2Lb2E6v4GWB3xmDDsAeBN5z/38KW1SrstvghNmgtFBEJ43uFRUR6YIPUGqd27FelfSJAD+yBsAj7+/2I/d6fiUhswOddid3/9gdexW6ntwE3hchbL+B77AHwa2z5b8Ge0HwjIilBb3E5eTgG27/xFXAyMBuYiT3ZeBv4COgPzKmNWqSI/Ad4E/sd38CWZUdguog8GOItI7FlNQXb1+Xv73rZWRaD3d7fBvoCX4nICQGfdxy2RnMgMAN4EnvyeJ/zfrD9OXc6zzc7z+dX8Sv5B0qFqvmchz152R3itU+cx/+IyJMi0ltEovwvGmNyjDFvG2NWhHhvjYj0GtXZztkK2I03EbthHgJcY4z51Z9QRI7GHuxfN8ZcHLA8GruT9BSRA4wxKympCV1hjJkWkPYpYDR2p5hTTp7GY8+u/guM9deMROQW7AY1AhtYQnkNG2yGYs9C/AZgDzL+jtHq5K8qxoiI/2AWBaQCg7A70qCg6v0o7I46whjzfEBe7sQejC/EOTiJyGBs08J7wBD/qEwRGU1Qp6+I9ASux+7MJxljspzlb2APSFWVChzkrxk471+MPaud6qS5FlszfQq4LuA3e5gQB9YQ3seelAzFnjX7v0MScCrwpTFmnYgcgg1KrxhjLg1INxt7cLoSe3CuEc5JWxL2gP6Es/jOgNfD2Sf8DgH+bYx5OOAzPsJuc8cDHzn9mf/B1m56G2PWOWkfBxYE5TEKG8higTOMMR8FvPYAtvbwMPb38nNja4T9jDF5TtrFzveMBQ41xuxylk/Dnrj2wx5oK9PBqY2HMj+gBn8ccCOwHDglYPtKAz4H/u30yQR+3+ZA98DBCiJyPrb29wZwqX/fEpH7ge+AV0Rkf2NMPnZ/iAH6GGP+dNJ5sCeOl4rIDU6tdpKITAQ2hdn/swA7COIcbJn783gQtqZ3V6g3GWNmi8gU7LHgGucvU0QWYYPYTP82EEJF5Q3wW2DttDyRXqM6C3t2PRFbg7kBOBzb4dc0MKpjd5rLnHTFnA3DPwqqufPo/949gtZxG9DKGFNRELgAe9C6Jaj57klsR/Yv5b3RGPMV8AdwXtDnDnUeX6+B/FXF9ZSU6wTsBtgG23zTJijtx8DV2LPCYsaYtdjv0jxgsf/gfFPQpQNTgFJNZtjmOhdwmz9IOeudQ8kZXFW8GNh85ZTxDmyzW2C+soAJQb/Zndih+RUyxuRiz0YPFpGDA146G3vgDP7dRESaBKTz1zzGUz0TRcTn/wO8Tv7nYE90bjTGvBiQPpx9wi8HW2v2p/VREgA6OI+nYwPk44EHKGPMdwRtJ9jg0gWYHhik/N8HW8O9KLC25pjiD1KOr5zH5/xByrEkKG+V2Y+SbT/4r39Ausucx5uCtq9/KPkdrwha9+8hRtT5A/CYwBNAJxBNwe5vJzmL/dvPUQHpCrAnP6nVHeBkjPG3Qh0tIq0CXjoPW8su9wTRGPMvbNP/R9jaeRPsdvAY8KeI3C8ioeJJReU9EdsiUalIr1GVuhZDRBpjq8V3YWsvB+A0KTk7zMsiEi32egDB9nscjq2xgK09gG0+uANbOxkqIh9jd8YPK+r/cZoXOgMLnINXMedgO64K3+l1bF9JP2xTYQz2gLfEGPN7dfIXhuJ+ImfjSsLWOP6LHaJeXO5OG/pyEUlwztA7Y8v9SOwBKDCQHglkBLd/G2O8IvI19jcJTAsBzYwBFlOy81ZmZYhlmdgdCRGJw7atLwvsC3HylSUiP1D6AFWe17Db2lBKDvzDsP15M53/f8I2bfUGNom9bm0u8IH/DLmaAoenNwHOB9o6eRtpjMkJTBzmPuH3t3N2H8hfbv5gcpjz+F2IPH6FPbHx8/ftLghOaIzJE5Fvsdv/gdhr+fx+D0rub5IKLkf/fhgc6MrzpTGmfxXSdceeCIQa6u9fdljQ8lC/cQ9sHkeHaPk9MOCz5mBbAM4G3hSRu7Hbzlzg8xC/yZ56B1uzPwfbtAtOs5+zP5T7Ruckco7TD9sX22w+CHtMGI8NtMHHwKqWd4UivUZVijFmtzFmGbaQ1wOXBbb7i+2Y/xvbwfoGtureCEh3kric9WzAHihfxJbBRdidfZOIPBvi7M6vqfNYnTMbf3+HvxZ1GrYD1n9WXp38hc0Y4zXGbHfOdv3XUdznf11E4kTkUWx7+AInT8OxfQzBA0eaUf61ThtCpN0dWJuqIG1F8kIs8+H81timQcLIV3nmY2soQwFEJBV7sJ/j7xNyah8nY5sHN2J/2yewZ5yfBDRj76n5xphJzt9Y7IFuAXbwwcOh3lDVfSJAeeUZmNa/H+wKkXZb0P/+muXO4IQOf/kH9zGF6ispL3+1oQmQGypAOCc82ZTNc05wWuy+HUfo2sRgJ02Ks9652ObVOdim/+uwgWqjiFxbze/j9xm2xeEcABHpgj2Rm1nRmwIZY7KMMR8aY27EnrSOwG4j19ZGXyHsZYHKz9l4/E0B3aC4LfgZbBvs2UB7Y0xTY8xp2Hbm4HX8aYz5P2zTx9HYEWAbsR2iIdtqsc1HYPvKynBqfJXlfSXwLTDYadYbiu24nlED+asWY8zP2ODTymmLB3gE2+T6IXYnSjXGtDXGXEjZg09xTSaE4OWZQFw5A0PKW8ee8B9Mq5qvkIwxXmxn+gEichj2IBNNwAmGky7LGHOHMaYTtgZzLbYfbgBBv3F1GWN2YzvvN2PP2K8KfD3cfSIM/ubSpBCvJQT97y//4CZlP3/Qy6hGfmrDLqCR0x9XilNLj6dqec4C1hpjXBX83ehPbIz50hgzEHuCdRowGdtv9YSInFbdL+U0JX4A9HcGsfib/UINS0dEmojIKqefNdT6fMb2XX+CLZO21c1jKHtloHL4N3D/wfJC/6Mx5n9OH4pfV+fRBXYqEBF5WkSaGGOKjDFLjDF3Yme9IOCxFOdMai3Q3WmyK+b8v1lE5lUh769hN8QTsMOePzHGbAlY1x7lr7qcoNEY2+ThD8oXYmtPQ4wx840x25y08ThD1Z0Od7Bn7W2D2r/9egX9vwzb7BTqmq3gtHvMaddfhR3KW6om6pwo9Axjdf7a8CBss9sOAga1iMhhIvKw00SKMWalsVPc9HHycFTwdlNdxpjN2D5GgEeDam1V3ifC5J9m59gQrwWXp38kWJ/ghE6zcx/stvb3HuSjNpWbb2eZiwr6owP8iN0nWga/ICJniMg9zokPInK90+Tnbz36yBhzDXZEMdTcfv8O9iRrIPaE6+Ogfr9izv6TBAwQkRYVrNPfZ1orl87slYFK7HDX/tgzO//oOX9bdYugtJdQcmGw/+z9QOzOHdiWDiUdshXtNK9hf7g7gpZfjz3If1pZ/rFDXguxzTUJlBwA/aqTv+q4Dtuc8UlAf0cutumi+MzSOcA/jj2DgpJynYbdgR8OHAQiIhdT0idFQFqAewObC0TkeGp+aqxp2JrTpKDlt2CvUasSp6P8J2zfVH/saKfApqhY7CjC2wOCN85nN8WO0qqpvobAfL0LzML+dlMCXgpnnwjHh9ia93Vir4/yr/dAbP9HoEXY/qZzReT0oNfuxF5r91ZQOUaCl5zH+wNaF/yj/vzNrK9WcT0u4KnAkxTnZO4Z7DboDxKnALf5T3QCdHAeA/f7AmxNa098jD05+Bf2RPHtStI/hd22Z4Y6CRU7B+BJwLvVHfBRnkgfTHF20BliFHAw9kwgCrg+4ID6GvYA8q6ITMc2LR2F3SG3YJvQ/P0VU7FNaA+KvYDuR+f1Idi28fsryNN92OubbhORfthRRwc6y5ZiByRUyBizRUQ+wVbtd1P2erAq5895vT8BQ2urIHB4OtiNsC92hNZObD+G32vYg+93IvIedps5Bdus9Q+Qhi3XjdgAPBzbp3awiHyB7WgdiG1+aoZt5sQY87XYi5yvBlaIyFzsAXUwtqZSnLYGPIatAY0XkT7Y3+lw5zvvILymxtewc01C2Wa/pSLyDvY7fC8in2MDwdnY71M8BNvZri/DTjHzUtjfqKzrsM2Lp4rIBcaY6YS3T1SZ0+k+AtuvsVRE/P0b52O3ieSAtF4RuRR7cPxARD7ATix9DLZJO50aHLJfU4wxC5y+2bHAj06+wW7LrbATAJcZIBLCS9ga+GDgJ2dgVDR2X04Fxhtj/nDSTsQ2r38hIm9j++EPwra6pFP6hHY9cKDYYeMfGmNCNt2V891yReRDJw95lNPsF+A+bD/WecDvzndYid22e2Fr1r9RUrMPVNnwdIBvTNkRoaVEeo0qcHj6ROyIkqOwBXu8Mab4jMYZkTIMuxNcjD0IxGFHzp3qJDvdSbsdu7NOwXYGjsFugB9iZ4Yoby4s/+i+47BnVW2xNakjsGcdJ4dxxuzf6P7n9DUEfkY4+etP2aG1lQkcnj7RWX8z7MWgRxhjAps0bnPSeLFnYOdgLzo8BXtxLpSUqw+7Q96H7SAejR1lNhx77Qk4MyY4rsEepHzYgHWU8/+LIdLuMWNHaJ6IHeXU2flc//DalWF+zhvYslhHiJFs2O96C/ZgNBK7Ha7GXp8WOHS8A7ZcLwvjs8tljFmP/a0A/isiTcPZJ/bg8/wXS3+P7Wc9E3tB8a0h0n6FrVHPwAao0djt4x7gKH9zcqRx+o4uxm7vF2EP7CuBwcaYKl1q4OwT52H3uWxsjXMo9uL5c4wxDwak/RZ78jQP2y0wFtsH/zhwXNBx4hrsKMMrsMfJcPkv/p1XWS3IGFNojDkfe6HwR9jf8nrnu8Rht/cjTOhZeSobnj6Rkm2xXC6fz1dZGqWqRETaATtDbfgi8iW2/yLBGONz2uzzQx2kRORl7HVWLQL77qqRrw7AP8EnBM5rf2NHHx5U3c9RStWOSK9Rqb3LOGCn0yRaTER6Yzug55uSC24vBjKcZqHAtJ2wtbZfayJIOZ7CXkm/f9BnDcEOA/4i5LuUUhFBa1Sqxoi9qPRrbEfvO9h29I7YPpo87HQ76U7attiBCY2wc+6tpuQ2BLHAacaYGgkgInKm8xnbsIMOMrCj3gZi+9Z61GBQVErVMA1UqkaJyOHYNuve2M76f7AjIe82QTNWiJ0h/hZse3wr7MCGhcD9poZnGndGE96E7U9sig1Qs518aZBSKoJpoFJKKRXRIn14eo37/vvvffHx8ZUnbADy8vKIja2x2Zj2WloOlpZDCS0LK7AcsrOzt/bo0SOtkrfUigYXqFwuF127dq08YQOQnp6uZYGWg5+WQwktCyuwHJYtW1Zvs4foqD+llFIRTQOVUkqpiKaBSimlVERrcH1USqmqKygoYN26deTm5laeeB9SUFBAenp65Qn3QXFxcbRt2xaPZ0/mK64dGqiUUuVat24diYmJdOjQAZdrT+4IsnfKycmhIY4O9vl8ZGRksG7dOjp27Fjf2SmmTX9KqXLl5uaSmpraoIJUQ+ZyuUhNTY24GrQGKqVUhTRINSyR+Hs36EA154857C4oM6G2UkqpCNJg+6i2525n/MLxTOw9kfMOOK++s6OUCmHJkiWMGTOGzp074/P5yM/PZ9KkSRx0UM3elWX8+PF8+umnfPXVV8TE2Bvn/vLLL5x77rm88sor9OrVi+eee46vvvqKwsJCXC4X48aN45BDDmH8+PH88ssvJCcX3y+SQYMGcf7559doHhuyBhuo4qNtR+nOvJ31nBOlVEWOPvpoHnvsMQAWLVrE448/zrPPPlvjn5OWlsaCBQsYMGAAAB988AHt2rUD4Pfff+fzzz9n+vTpuFwu0tPTGTduHO+//z4AN998M3379q3xPCmrwQaq2KhYPG4Pu/J31XdWlNorvLNsHW99t7ZG1zmkZzsG92hb5fSZmZmkpKQAsHTpUp566il8Ph+7d+/mkUceoXXr1lx//fVkZWWRk5PDDTfcQJ8+fZg7dy4vvfQSbrebHj16cNNNN5VZ9xlnnMHs2bMZMGAAXq+XX375hUMPPRSAxMRENmzYwMyZM+nbty9du3Zl5syZNVMIqlINNlC5XC4SYxI1UCkV4b755huGDx9Ofn4+v/32G5MnTwZg1apVPPzww7Ro0YJnnnmGjz76iAEDBrBjxw6ef/55MjIy+Ouvv9ixYwdPPvkk77zzDvHx8dx8880sXryYY489ttTndOvWjXnz5pGdnc3SpUvp1asXq1fbO9O0aNGCKVOm8NprrzF58mTi4uK44YYbOOWUUwB4+OGHmTp1avG6JkyYgIjUUQnt+xpsoAJoEtNEA5VSVTS4R9uwaj81JbDp748//mDYsGEsWLCAFi1acO+999KoUSM2b97MEUccQZcuXRg6dChjx46lsLCQ4cOHs2bNGrZt28bIkSMB2L17N2vWrCkTqABOPPFEPvvsMxYuXMi1117Lo48+CsDff/9NQkIC999/PwA//fQTI0aMoFevXoA2/dW2Bh2oEmMSySzIrO9sKKWqqFmzZsXPb7/9dj755BMSEhIYN24cPp8PYwy7d+/mueeeY8uWLQwbNoyZM2fSqlUrXnzxRTweD7NmzSp3ZvSBAwdy33334fP5ivunAIwxzJgxgylTphATE0PHjh1p0qQJUVFRtf6dlQYqrVEpFeH8TX9ut5vdu3czfvx44uLiGDRoEBdddBHx8fE0a9aMLVu20KFDByZPnszcuXPxer1cd911pKSkcNlllzF8+HCKiopo06YNp512WsjP6tSpE9u3b2fQoEGllp988smsXr2a8847j0aNGuHz+fj3v/9NYmIiULbp78gjj+S6666rvUJpYBrcHX6XL1/uO/zwwwG46cubWLl9Je+f/X4956p+6D13LC0HK1Q5NNSyaahTKPn5f/eg+1Et69GjR8/6yE+DvuBXa1RKKRX5NFBpoFJKqYjWoANVk5gm5BXlkVeUV99ZUUopVY4GHagSPbYjVGtVSikVuRp2oIrRQKWUUpFOAxUaqJRSKpJpoEIDlVKRasmSJfTu3Zvhw4dz8cUXM2TIEH799dcaW/8NN9xAfn7+Hr//ySefpGvXrmzevLl4WUZGBgcffDCzZs0C4N133+WSSy5h+PDhDBs2jEWLFhW/95RTTmH48OHFf1OmTKneF9pHNegLfpvENAE0UCkVyWpz9nT/equjQ4cOzJ07l8suuwyADz/8kFatWgGwa9cunn76aebMmUNMTAybN2/m/PPPZ/78+QBcdtllXHDBBdXOw76uQQcqf40qM1+nUVKqUiumw/LXanadh18M3at+oK5s9vSOHTsyefJkPv30U1JSUsjJyeH666+nS5cu3HTTTeTn59OxY0e++eYbPvnkE0444QTmzp3LxIkTiYmJYf369WzZsoU777yTI444grfffpvXX3+dpKQkPB4Pp59+Oueee26pPJ1++ul89NFHxYHqiy++4PjjjwcgJiaGgoICpk+fzvHHH0/79u359NNPcbsbdGNW2DRQoTUqpSJZOLOnH3/88SxcuJCZM2dSUFDAmWeeCcAzzzzDiSeeyEUXXcTixYtZvHhxmc9p3bo1d911F2+99RbvvPMOHTp04Pnnn+e9994jJiaGSy65JGT+mjVrRnx8PGvXrsXr9dKyZUtiY2MBiI2N5eWXX+bll1/myiuvpKCggBEjRnDhhRcC8NJLL/Hhhx8Wr+vqq68OOVluQ1crgUpEooCpgAA+4GrAA8wGVjnJphhjZojIROAMoBAYY4xZKiKdgZec9/4MjDbGeMNJW5V86j2plApD9wvCqv3UlHBmT1+9ejWHHnooUVFRREVFccghhwCwevVqzjnnHAB69gw9C5B/qqCWLVuydOlS1qxZQ6dOnYqnUvJPvRbKGWecwZw5cygsLOTMM88sDoSbN28mNzeXO+64A4A///yTK6+8kh49egDa9FdVtVX/PBPAGHMsMAG4F+gBPGqM6e/8zRCRI4B+QC9gGDDZef+jwARjzHGACzgrnLRVzaTek0qpvUvw7On33XcfDzzwAM2bN8fn89G5c2d++uknvF4v+fn5xQMvDjjgAJYvXw7AihUrQq7b5XKV+r99+/b88ccf5Obm4vV6+fHHH8vN1ymnnMJnn33Gd999V3zrD4CtW7dy8803k5WVBUCbNm1o2rQpHo9nzwqggaqVGpUx5j0Rme38ux+wAxuoRETOwtaqxgB9gHnGGB+wRkSiRSTNSful8/65wMmACSPtu1XNq96TSqnIFs7s6SJCv379GDJkSHFAiI6OZsSIEfz73/9m7ty5NG/enOjoyg99KSkpxc10ycnJ5OXllfu+xMREWrZsSbt27Ur1Px188MHFIxbj4uIoKiri/PPPZ//99wfKNv117NiRu+66q5oltu+p1dnTReRl4BzgPKAN8KMxZpmI3AY0xQawDGPMFCf9AuAKYIExprWz7ARn2W9VTWuMubi8PC1btszXqFGj4v9v/eVWEqITuFVurdkvvxfIzc0lLi6uvrNR77QcrFDlUFBQQJcuXeopR+Hbtm0bn3zyCUOHDiU/P5/Bgwfz3HPP8fvvv9O0aVMOOeQQvvnmG1544YVSt+UI5vP5KCoqYtq0aYwYMQKfz8cVV1zBNddcU9xsty9btWoVHo+n1DaRnZ1db7On1+pgCmPMpSIyDlgCHGOMWe+89C7wJPA/IDHgLYnY4OUNsSwzjLTlcrvdpW5b0Hxdc7IKshrkrQwa6i0cgmk5WOXd5mNvut1Fq1atMMZw8cUX43K5GDJkCPvvvz8+n49bb72VqKgovF4vt912W4XfKycnh8TERAoLC7nwwgvxeDx069aNY489tkwT4b7I4/GEus1HveWntgZTDAfaGmPuB7KxwWSWiFxrjFkKnAgsAxYDD4nIf4C2gNsYs1VElotIf2PMfOA04Avg9zDSVlmCJ4GNuzfWxNdWStUzt9tdfLv4QJ06dWLGjBlhr2/s2LGMHTu2JrKmqqG2alSzgGlO85wH2x+1FnhSRAqATcBIY0ymiCwEvsYO7BjtvP9GYKqIxADpwExjTFFV04aTUR1MoZRSka22BlPsBoaEeKnMBQLGmEnApKBlK7Ej/PY4bVXpYAqllIpsDf7y6MSYRL0nlVJKRTANVDo7hVJKRTQNVBqolIpYgbOnDx8+nHPPPZfrrruuWjOeg501fcmSJTWSx7Vr13Lqqacybty4GllfoBkzZlBQUFBq2axZsxCRUhcuFxQU0KtXL5588kkAvvzySy699FIuueQShgwZwvvvv1/83v79+5easf3uu++u8XzXtAY91x9ooFIq0gVOoQRw44038vmH36cNAAAgAElEQVTnn3PqqafWY65KLFu2jP79+zN+/PgaX/ezzz7L2WefXWb5/vvvz5w5c+jevTsACxcuJDGx5OqdiRMn8v7779OkSROysrI466yziucQHDhwIDfddFON57U2NfhApbf6UKpq3l/9Pu+uqvKkL1VyTpdzGNRpUJXT5+fns2XLFpKSkigqKuKOO+5g06ZNbNmyhRNOOIEbbriB8ePHl5oJ/YEHHuDggw/m9ddf5+233yYtLY2MjAzA1kRuueUW1q1bR1FREZdffjmnn346//d//8dBBx3EqlWraNSoET179mTRokVkZmby4osvkpSUBMCGDRt45plnyM3NpX379nTv3p27776bqKgoYmNjufvuu/F6vYwaNYrk5GT69u1L3759ueeeewBITk7mvvvuo6CggDFjxuDz+cjLy+POO+/k559/5p9//uGGG27g6aefLlUOffv2ZdGiRXi9XtxuN3PmzOGMM84ofj0xMZFXXnmFU045hc6dOzN37lxiYmKq+3PVG2360xqVUhHNP4WS/xYbJ510Er1792bjxo10796dF154gZkzZ/Lmm28Wv6d169a88MILDB8+nBkzZrB161ZeeeUV3nrrLZ5++uni5rQZM2aQkpLCm2++ybRp0/jvf//Ltm3bAOjWrRsvv/wy+fn5xMXFMW3aNDp37sy3335b6nNGjhzJwIEDufDCC5kwYQJ33HEHr732GhdccAEPPPAAAP/88w8vvPACI0aM4Pbbb2fixIm8+uqr9O3bl+eff54ff/yR5ORkpk6dyh133EF2djbnn38+aWlpIe+Z5fF46N69O0uXLiUrK4usrCxatmxZ/PqLL75ITk4OY8eOpU+fPjz77LP4ZyGaPXt2qaa/9957r+Z/tBrW4GtUek8qpapmUKdBYdV+aoq/6W/79u1cccUVtG3bFrC1kZ9++olvvvmGhISEUv1WgTOhf//996xZs4bOnTsX1yq6desG2FnVjznmGAASEhLo1KkTa9euBew8fQBNmjShc+fOxc/z8sofIbxly5bizz7yyCN55JFHAGjbtm3xZ69evZo777wTsDW6Dh060LdvX/766y/+9a9/ER0dzahRoyotl4EDBzJnzhw2btzISSedVBx8d+7cyYYNG7j55pu5+eab2bx5M9dee23x99kbm/60RqU1KqX2Ck2bNuXhhx9mwoQJbNmyhVmzZpGYmMgjjzzCFVdcQW5ubnGtIXiaow4dOvD777+Tm5tLUVER6enpgJ2x4rvvvgMgKyuLlStXFgfCPdG8eXN+++03AL799ls6dOgAUGqi2o4dO/Lggw/y6quvcvPNN9O/f3+WLFlC8+bNefHFFxk1ahSPPvpo8ffwekPftahXr16sWLGCjz76qFR/XX5+PjfccANbt24FIC0tjWbNmu3VTX8NvkYVFxVHtDtaA5VSe4HOnTszfPhw7rnnHq699lpuvPFGVqxYQUxMDPvttx9btmwJ+T7/TOjDhg0jJSWleJ6/IUOGcPvtt3PBBReQl5fHNddcQ2pq6h7n75577uHuu+/G5/MRFRXFfffdVybNpEmTGDduHIWFhbhcLu69916Sk5MZO3Ys06dPp7CwkNGj7cQ7PXv2ZOTIkbzyyitlgq/b7ebYY49l48aNJCQkFC9PS0vjtttu46qrriI6OpqioiL69+9Pnz59mDVrFrNnz+aHH34oTp+QkMCUKVP2+DvXhVqdPT0SLV++3Bd8A7R+M/oxoP0Abu99ez3lqn7oZKyWloNV3qS0DbFscnJy9qrJeGua/3cPmpS23mZPb/BNf6Dz/SmlVCTTQAUkehLJLNDBFEopFYk0UKE1KqUq0tC6Bxq6SPy9NVChgUqp8sTFxZGRkRGRBy9V83w+HxkZGRF3x+sGP+oPNFApVZ62bduybt06/vnnn/rOSp0qKCjA4/HUdzbqRVxcXLWG6NcGDVToPamUKo/H46Fjx471nY0611BHO0YqbfpD70mllFKRTAMVOjuFUkpFMg1UaKBSSqlIpoEKDVRKKRXJNFCh96RSSqlIpoEKrVEppVQk00CF3pNKKaUimQYqtEallFKRrFYu+BWRKGAqIIAPuBrIBV5y/v8ZGG2M8YrIROAMoBAYY4xZKiKdq5s2nPzqPamUUipy1VaN6kwAY8yxwATgXuBRYIIx5jjABZwlIkcA/YBewDBgsvP+aqUNN7Mul0tnp1BKqQhVK4HKGPMeMNL5dz9gB9AD+NJZNhcYAPQB5hljfMaYNUC0iKTVQNqw6Xx/SikVmWptrj9jTKGIvAycA5wHnGSM8U/BvAtIApoAGQFv8y93VTNtubxeL+np6WWWe4o8bNi2IeRr+6rc3NwG9X3Lo+VgaTmU0LKwIqUcanVSWmPMpSIyDlgCBN7XORFby8p0ngcv91YzbbncbnfIySbbbGjD5uzNDWoiSp1409JysLQcSmhZWEG3oq+3fNRK05+IDBeRW5x/s7HB5DsR6e8sOw1YCCwGThERt4i0B9zGmK3A8mqmDVtKXArbcrbtyVuVUkrVotqqUc0CponIAsADjAHSgakiEuM8n2mMKRKRhcDX2KA52nn/jdVJuycZTo1PZVvuNrw+L26XjtpXSqlIUSuByhizGxgS4qV+IdJOAiYFLVtZ3bThSolLodBXyK78XSTFVtjNpZRSqg5p1cGRGpcKQEZORiUplVJK1SUNVI6U+BQAMnI1UCmlVCTRQOUorlFpoFJKqYiigcqREmdrVDryTymlIosGKkdybDJul5ttuRqolFIqkjTsQPXdNMjZDkCUO4rk2GRt+lNKqQjTcANV1j8wewz88l7xotT4VG36U0qpCNNwA5Unzj7mlUxEmxKXojUqpZSKMA04UDWyj/m7ixelxKVoH5VSSkWYhhuo3FE2WOVnFS9KjUvVC36VUirCNNxABRDTuFSNKjU+lezCbHIKc+oxU0oppQJpoAoMVM5Fv9r8p5RSkaOBB6qEMn1UoBf9KqVUJGnggapx6T6qeK1RKaVUpNFAFaJGpUPUlVIqcmigCtX0pzUqpZSKGA08UJXuo4qLjqOxp7EOUVdKqQjSwANV6T4qcK6l0qY/pZSKGBqoAmpU4MxOoaP+lFIqYjTwQJUARXlQVFC8KDVea1RKKRVJGnigamwfdb4/pZSKWBqooMw0Sttzt1PkLaqnTCmllArUwANVgn0MqlH58LE9b3s9ZUoppVSgBh6o/DWq0jOog15LpZRSkSK6plcoIh7gRaADEAvcA6wFZgOrnGRTjDEzRGQicAZQCIwxxiwVkc7AS4AP+BkYbYzxhpO2ypktp48KNFAppVSkqI0a1cVAhjHmOOBU4CmgB/CoMaa/8zdDRI4A+gG9gGHAZOf9jwITnPe7gLPCSRtWTkMFqnhnGiW96FcppSJCjdeogLeBmc5zF7YG1AMQETkLW6saA/QB5hljfMAaEYkWkTQn7ZfO++cCJwMmjLTvVjmnxX1U2vSnlFKRqsYDlTEmC0BEErEBawK2CfB5Y8wyEbkNmAjsAAKrLbuAJMDlBKTAZU3CSFshr9dLeno6ANHZm+kCbPz7d3ZE22U+n48oVxQr160k3ZUe7tffq+Tm5haXRUOm5WBpOZTQsrAipRxqo0aFiLTD1myeNsa8ISLJxpgdzsvvAk8C/wMSA96WiA1e3hDLMsNIWyG3203Xrl3tPzkt4QNoldqEVv5lQOovqbgau0rS7aPS09P3+e9YFVoOlpZDCS0LK7Acli1bVm/5qPE+KhFpAcwDxhljXnQWfywiRznPTwSWAYuBU0TELSLtAbcxZiuwXET6O2lPAxaGmbbqPGX7qEDn+1NKqUhSGzWqW4GmwO0icruzbCzwmIgUAJuAkcaYTBFZCHyNDZijnbQ3AlNFJAZIB2YaY4qqmjasnEbHQFRMmYlpU+J1vj+llIoUtdFHdT1wfYiXjg2RdhIwKWjZSuwIvz1OG5YQE9OmxqXyx44/qrVapZRSNaNhX/ALZe5JBTZQbcvdhs/nK+dNSiml6soeBSoRia3pjNSbEPekSolLIa8oj+zC7HrKlFJKKb8KA5WIzAh4fmPAS3NrLUd1LUTTX9O4poBeS6WUUpGgshpV84DnZwQ8d9VCXupHBYFqe65OTKuUUvUtnKa/wOC073TexCSGvMsvaI1KKaUiQWWBylfO831HiD4qrVEppVTkqGx4+sEi8ga2NhX4/KBaz1ldCdX0F6t9VEopFSkqC1RDAp4/U87zvVuIQNXI04i4qDitUSmlVASosOnPGPMlsMN5/Bo4BOhCuFMVRbKYBCjYDd7St7FKiUvRu/wqpVQEqGx4+ljgORGJBh4GTgIOBR6rg7zVDf89qQpKXzPVNK6pNv0ppVQEqKzp73zgGOxAiguBLsaYHSLyVa3nrK4E3jwxNqF4sQYqpZSKDJWN+ttljCkCugN/BNyqYx+6jqrszRPBafrTPiqllKp3lQ5PF5EDgMuBDwBEpAv2rr37hhC3owc78k8DlVJK1b/KAtUE4FWgPfBfEekHfAbcXNsZqzPlBaq4puQW5ZJdoPP9KaVUfaqsj2oU8Au2qe8JIB474m8k8E3tZq2OFDf9hZ6dYnvedhp5GtV1rpRSSjkqC1Q9scHpdeAr9qW+Kb/iGlXZPiqws1O0SWhT17lSSinlqOw6qm7AOUAcMB7oDaw2xnxcB3mrG+UEKp1BXSmlIkOld/g1xvyMDVKISF/gfhFpZ4w5urYzVyfKafrTQKWUUpGhSreiF5FE4FzgAqAx8FptZqpOVaHpTymlVP2pMFCJyBBgGLAf8A5wtTHmrzrIV92JjgVXVNn5/qIbEeOO0UCllFL1rLIa1ZvAb8AP2KmT7hMRAIwxF9Zu1uqIy2Wb/4IClcvl0tkplFIqAlQWqI6vk1zUtxD3pAKdmFYppSJBhYHKmTV93xfiVh/gzPeXozUqpZSqT+Hcin7fVU6g0hqVUkrVPw1UELKPCnQGdaWUigRVGp4eDhHxAC8CHYBY4B7gV+Al7O1CfgZGG2O8IjIROAM7ye0YY8xSEelc3bRhZzqmMWRtKrM4JS6FnMIccgtziYuOC3u1Simlqq82alQXAxnGmOOAU4GngEeBCc4yF3CWiBwB9AN6YYfAT3beX620e5Tj8vqoYu1FvzpEXSml6k+N16iAt4GZznMXtgbUA/APzJgLnAwYYJ4xxgesEZFoEUmrgbTvVpQ5r9dLenp6qWWtsgtonL2T34OW795ug9f3v33P/o33r3IB7C1yc3PLlEVDpOVgaTmU0LKwIqUcajxQGWOyoHg2i5nYW4X8xwkyALuAJKAJkBHwVv9yVzXTVsjtdtO1a9fSC/9qCxvyyizP25IHq6BJyyZ0bRv0nn1Aenp62bJogLQcLC2HEloWVmA5LFu2rN7yUSuDKUSkHfAF8Kox5g0gsN8oEdgBZDrPg5dXN234/NdR+XylFvvn+9ORf0opVX9qPFCJSAtgHjDOGPOis3i5iPR3np+GvafVYuAUEXGLSHvAbYzZWgNpwxfTGHxeKMwttVjn+1NKqfpXG31UtwJNgdtF5HZn2fXAEyISA6QDM40xRSKyEPgaGzBHO2lvBKbuado9ynHgDOqe+OLFCZ4Eot3ROkRdKaXqUW30UV2PDUzB+oVIOwmYFLRsZXXThi1wBvXGzYoXu1wuUmJTtEallFL1SC/4hYBAFfqiXw1USilVfzRQQbk3TwSdnUIppeqbBioo9+aJoIFKKaXqmwYqqLDpTyemVUqp+qWBCioNVLsLdpNflF/HmVJKKQUaqKziPqrQTX+ANv8ppVQ90UAFFdeoYvWiX6WUqk8aqAA8jQBXuaP+QGtUSilVXzRQAbjd5d7qo11iO6JcUSxav6geMqaUUkoDlZ9/YtogaY3SGLj/QN5e+TZbsrfUQ8aUUqph00DlV06NCuCqw66iyFvE8z89X8eZUkoppYHKL6Yx5O0K+VK7xHac1fksZq6cycasjXWcMaWUatg0UPkltIBd5Qehq7pdhQ8fU3+aWoeZUkoppYHKL7k97Fhb7sutEloxuMtg3l31Luuz1tdhxpRSqmHTQOWX1A5ytkFe2QEVfiMOHYHb5Wbqj1qrUkqpuqKByi+5vX3cWX6tqkXjFpzZ6Uxm/zGbnXk76yhjSinVsGmg8ktqZx8raP4DuLDrheQV5TFr1aw6yJRSSikNVH7FNao1FSY7oOkB9GzRkxlmBkXeojrImFJKNWwaqPwSWkBUDOyoOFCBrVWtz1rPl+u+rIOMKaVUw6aBys/thiZtKm36Azi+3fG0bNySN357ow4yppRSDZsGqkDJ7SocTOEX7Y5mqAxlycYlrN6xug4yppRSDZcGqkCVXEsVaHCXwcS4Y5j+2/RazpRSSjVsGqgCJbWHrE1QkFtp0qZxTTl9/9N5f/X7bNq9qQ4yp5RSDZMGqkDJzhD1zKrNPHH1YVfj8/l46NuHajFTSinVsEXX1opFpBfwoDGmv4gcDswGVjkvTzHGzBCRicAZQCEwxhizVEQ6Ay8BPuBnYLQxxhtO2j3OdPG1VGsgtVOlydsktGFEtxE8ufxJFq9fzLFtjt3jj1ZKKRVardSoROTfwPNAnLOoB/CoMaa/8zdDRI4A+gG9gGHAZCfto8AEY8xxgAs4K5y01cp4FWanCHbZwZfRoUkH7ltyH3lFedX6eKWUUmXVVtPfauDcgP97AGeIyAIReUFEEoE+wDxjjM8YswaIFpE0J63/AqW5wIAw0+65Jq3B5a7StVR+MVEx3NLrFtbsWsO0n6dV6+OVUkqVVStNf8aYd0SkQ8CipcDzxphlInIbMBHYAWQEpNkFJAEuY4wvaFmTMNJWyOv1kp6eXu7rnePT2P33z2ysIE2wpjTl6JSjee6H5zjIdxBpsWlVfm99ys3NrbAsGgotB0vLoYSWhRUp5VBrfVRB3jXG7PA/B54E/gckBqRJxAYvb4hlmWGkrZDb7aZr164AvLNsHW99V7qZb1JBM3wb13HngkpXVUoBZ1EQu5Q7lv2PFoXnhfXe+pKdnU2jRo3qOxv1TsvB0nIooWVh9WkTxbUDDwdg2bJl9ZaPuhr197GIHOU8PxFYBiwGThERt4i0B9zGmK3AchHp76Q9DVgYZtpq+Se6Bc2KNof9Pg+pJHq7sz1qEV60r0oppWpKXdWoRgFPikgBsAkYaYzJFJGFwNfYgDnaSXsjMFVEYoB0YKYxpqiqacPJ1OAebRnco23phZ8dAYu+ZMaVR0JUeMXz7aZorvj4Ci48YTvndDknrPfWh/T09OLaZUOm5WBpOZTQsrAiodkPajFQGWP+Ao52nn8PlBm7bYyZBEwKWrYSO8Jvj9NWS3I78BXBrg0lowCrqGeLnnRO7sz036ZzduezcblcNZo1pZRqiPSC32BVvC9VKC6Xi2EyjPRt6fy49ccazphSSjVMGqiCJe9nH8O4lirQwE4DaexpzJu/vVmDmVJKqYZLA1WwJKfPKoxrqQI19jRmUKdBfPzXx2TkZFT+BqWUUhXSQBXMEweNm+9xoAIYduAwCrwFTF4xWe8CrJRS1aSBKpQq3peqPPsn7c+FB17I2yvfZtSno9iWu60GM6eUUg2LBqpQwrgvVXlu6XULdx5zJ8s2L2PIB0NYsWVFDWVOKaUaFg1UoSQ5NaqM6t2999wu5/Lq6a8S7Y7m8o8vZ8ZvM/D5fJW/USmlVDENVKF0GwoxCfDc8bByXrVWdVDqQcwYOIPerXpzz5J7mLB4ArmFld+YUSmllKWBKpSWh8DI+dC0PbwxBBY8DNWoCSXFJvHUiU/xr8P+xQerP+CSuZewNWdrjWVXKaX2ZRqoytN0P7hiHhx6Hnx+D3xye7VW53a5GdV9FE+d+BR/7vyTaz67huyC7BrKrFJK7bs0UFUkphGcOxWOHAFfPQnfPFPtVfZt25f/9PsP6dvSuenLmyj0FtZARpVSat+lgaoyLhec9iAcOBA+Gg+//q/aq+zXrh+39bqNhesXcvc3d+sAC6WUqoAGqqpwR8Hg56HtkfDOCPj762qvcogMYcShI5i1ahaPLXtMg5VSSpVDA1VVeeLhwhmQ1AbeHQkFOdVe5bWHX8uQA4Yw7Zdp3LvkXrw+b+VvUkqpBkYDVTgapcCZj9vplRb9t9qrc7lcTDh6ApcfcjkzzAxuXXQrBd6CGsioUkrtOzRQhatjXzjkPFj0GGz7o9qrc7lcjO0xluuPuJ45f8xh1Cej+DXj1xrIqFJK7Rs0UO2Jk++BKA/MHVet66sCXXnolUzqPYlft/3K0NlDufbzazVgKaUUGqj2TJNW0P8WWDUPzNwaW+3gAwbz8eCPGd19NMs2L2PY7GG8+uurNbZ+pZTaG2mg2lO9roK0rnbIurfmBkEkxiRy9WFX8/Hgjxmw3wAe+vYhHvr2IR1ooZRqsDRQ7akoD/S9CXb8DeuW1vjqE2MSebjvw1zU9SJe/fVVbv7yZvKK8mr8c5RSKtJpoKqOLidDVAz8+n6trD7KHcW4I8dxU8+bmPf3PK7+5Gqy8rNq5bOUUipSaaCqjrgm0OkESH+/xgZVBHO5XFx68KU8eNyDrNiygis+vkJvca+UalA0UFXXQWfZe1dt+L5WP+b0/U/niROe4M+df3LZR5exPmt9rX6eUkpFCg1U1SWngTu61pr/Ah3X9jieO/k5MnIzOPPdMxk7fyxfrPmCgiK9SFgpte+Krq0Vi0gv4EFjTH8R6Qy8BPiAn4HRxhiviEwEzgAKgTHGmKU1kba2vlNI8U2hYz87We2ASXYS21p0ePPDefOMN5n+23Q+/PNDPvn7E5Jjkzm+3fEM2G8AR7c6mpiomFrNg1JK1aVaqVGJyL+B54E4Z9GjwARjzHGACzhLRI4A+gG9gGHA5JpIWxvfp1IHDYLtf8Lmn+vk49o3ac+4o8bx6fmfMvnEyRzT+hjm/T2P0Z+Npv+M/qzYsqJO8qGUUnWhtpr+VgPnBvzfA/jSeT4XGAD0AeYZY3zGmDVAtIik1UDaunfgQHC566T5L5DH7aFv27482PdBFgxdwOQTJ+N2u3nLvFWn+VBKqdpUK01/xph3RKRDwCKXMcY/LG4XkAQ0AQKHr/mXVzdthbxeL+np6eF9oSpon3Y40Sve4o9W51aeuJakkcahCYcyf818fvn1F9yuis9DcnNza6Us9jZaDpaWQwktCytSyqHW+qiCBPYbJQI7gEznefDy6qatkNvtpmvXruHkvWp2XQAf3kRXzwbofGLJ8qIC+OwuWLsUug60E9o2aVXyus9Xo/1aA2MHsmjhIrxpXg5OO7jCtOnp6bVTFnsZLQdLy6GEloUVWA7Lli2rt3zU1ai/5SLS33l+GrAQWAycIiJuEWkPuI0xW2sgbf04ZDCkdobXz7czq3u9sGszvDwIvnoCcrbBvAnwaFd4fgA82xf+I3BXKjzdG+Y/AFvSq3091rGtj8WFi0XrF9XQF1NKqfpVVzWqG4GpIhIDpAMzjTFFIrIQ+BobMEfXRNo6+j5lNUqBEV/AB9fBp5PgzwU28OTsgHOfh27nw9bf4ae34I/50Lg5tDwUGqXCuu9soJp/v50/8PCL4bBh0LhZ2NlIjkvm0LRDWbh+IaO6j6rxr6mUUnXN1dBugb58+XLf4YcfXnsf4PPB0qnw8a3QpDUMe90GpMrs2mxnuPhxBqz7Ftwe6DwAktpCXBLEJ9tZMFpU3JwH8MwPz/D0iqf5YsgXpManlptOmzcsLQdLy6GEloUV1PS3rEePHj3rIx91VaNqOFwu6DUS5FR7jVVsYuXvAUhsAUeNsH9b0uH7V2HlR7D2G8jdCf7Z0zscZ2dul9PBHRVyVce1PY7JKybz1YavOLPTmTX0xZRSqn5ooKotye33/L3Nu8Kp99k/sLW03f/Aijfg2+dhxsUQHQ9NO9i/lP2h5SG25tZM6JrSldS4VBauX6iBSim119NAtTdwuSChOfQZA72vgZVzYc03sP0v+/fHfCjMsWmjYnB3OoE+TdrzxfrFFHmLiCqn5qWUUnsDDVR7m6ho6Hqm/fPzFsG2P2DjD7B+GfzyLn3W7+R/zZvx02tncJg7kZWuQpaTzXZfITu8BWRSRLSrEa3WHkhK2kH02O9EuqQcUH/fSymlyqGBal/gjoJmXezfoefByffQe+WHRC25lQeLNrO9aCPr3SWXnCX6XCT6YLdvBzs3boKN83H9MJlBeT6u8SXRMiYJvIVQlG/7xpLb26H3zbpAo2YQHVvy52kMnnjbFxfftOw1YfnZkLvDDg6JirZNlp44wuItKrc/Tim179NAtS9yR5F04JkcvXYOSzctpXfrPoxodwLHtD6GZo2a4XF7AEj/+Ue6JOWxdc1CXt+4kNddq/mYLM7zwWFRjegSl8R+xBC9dRWs/Bi8lczSHhVrRykmtbEBasca2L2lbLqEFjbwpewPMY1DXztWmGvvnpzxh72NSqNU23eXdqB9z66NkLkB8jLt+pq0hsTWdoRkbALEJNhprQrzoCjP3uCyTQ/7mbU8cbCKAN4iKMgBX5E9mYoq51BXmG9PpApyIDrOnkRFx5feJosK7XWQu7dCQbbdflxR9tFb5PwV2m22MNeuy+WyJ2+xSXZ7dUcBLrtNulz2f1eU3S498fbPHW3fW5Bt/7yFNh/+E7XoOPvnctnX87Igf7c9ofQW2v3T5U8Xa9dXlGe/Y1G+XYfbY5eD855CW0Z+LjfEp9iuhviUWvt5wqWBah/2xAlPUOgtpJGnUegEUR6i23WjZbsjuZGxDN21jieWP8H0v+bxmm8XFNn5BNu0aUMbOZy2niRaRSfQ3JNAy+gEGrtc7M7LZFdeJrn5u2iSu4vUnJ2k7vqHlJgEouVUWxuLT3F25gIbwLb/BdtW2+BXmGenEyYoeLijoel+0L4XJJ8PWVvgn9/ghzftzpfYEhJb2evRdm2CDcvtgJPKNG4O7Y6yw/2dnbZZthdyDrdBNnz8k/EAABGYSURBVLGVE+gaOwc4z54FtqICew2dz2uDbHkHykhQVADZGXiyNkD+fhATYnvx+exvVZjjHDij7UE2Kqby71ZUAHm77Pt8XntgzNkB2VvtwT9/d8lB01tkX/enDVSQA9kZNmjk7XIO+k7AyNlhf//d/zifFXRSFRVbEgxcLsBl15e/K2SWu4ITSDw2+DRE7mgSj74TImCYfgTvPaq6YqJiwrrlR9vEtjzU9yHuPvZu/tz5J6u2r2LVjlWs27WO9Vnr+Wnrz2TmZ1a+Ig9EubbTLC+Hllnbae5tTlp8GmkJaaTGtSa5Y0+SYpNIik2ibWJbYqNiq/6l/Ge6LhdZ+Vlsy91GUmwSiTGJuIsKKczdwdbMNWzKXENCdDydkjrh8sTZg9faJXYQyvplNmB6C6CogGa5O+GXCq4ndEfboOZyOQdarz2IxSbauzx7GpWcURfk2lpeflbpdcSn2IvC3R57gHW7IS7ZBrHGaTZwehrZP5cLtv0JGb/bWfmjYuz745MhtknJGXhMY1ubTGxl15G7AzLXQ+ZGe0DPy7TfOzfTXuKQuxPydpacyUfF2HzmbAOgM8Ac7Gc0bmYDTEG2c5afg72bTgjR8bYcYpvYsvKXUWEu5GwvWxbV4S+z2MSSz/F57fI0gQ59bK3aE29rFa4oJyA5tQ9/eny2rOOb2j9PfMnvV5jDP5s3kpaSbMsgJsH+do2b2ZOXwM91Rzs1lYAaj8epkeXtKtkWfF67zP8+f0AuzCuphRUVOL9rgn2McrYVl9umL8yx6b2FNk1MY/sYHVNSU/KXe2GuTRcVa1+PirGvFRXY5Ti1Ond0SS0P7GvZ22zAz9lObmOpud+uGjRQqTJio2I5MOVADkw5sMxr2QXZbM7ezObszewu2E2iJ5HGMY2Jj4pnZ/5OtuVsY2vOVrbkbGHT7k1s3r2ZVdtX8fWGr8kqKHvA8rg9dE3pSre0brRo1ILM/Ex25u0ktyiX1gmtaZ/YnraJbdmWu42/dv7Fnzv/5O/Mv1mzaw3bcrcVr8ftcpMYk8iu/F14A87EU+JS6NmiJ0e2PJIjO/dj/x6X4wqqIf32y090bZ0IO9fZ2llBNt68LDJy/iGFKKL8tUEoOXAUFdgDUG6mPQBGx5Q0ucQ6F2jHJdsDQHaGrRHmbCupKXiLbODY8qtzUNhBqUDgaQypnewF3t4ie8DPWG0PfoU5JU1EIbnswTquic1LbCIkt4O4Q5wDvM82BRXl24N1QnNo3IwNW7bTuonb5nX31tLNUp5GJc1i7mgnyOfbZqW8TPuXm+kEcaeMomNLAkFsYsBB0W3z1jjN9nnGJpQcaN1RTiB3HgNr2lWpvdWQrenp/H97dx8jR3kfcPw7s7Mvs7e757tb39nmztgY89hqoFHdNAVTh6iBEEgbQtQqraKGohTSUrVpUzUUERGhVgK1Tds0oU3TUMh7FWiihijEadpQAmnBiLitsH8uhlAT5PO9eX0vs2+z0z+eufWe785nG7O3x/4+0um8z+4888zj3fnN88ze81u/xEiiFtaYrk0zXZ3mROUEY8EYY3NjHJs5Rr1Rx3VcXMfFwWm+D8MoJKgHzNZmCeoBCSdBKpEinUiTTqTJ+ln8fD/pRJp6o06tUaMSHme2MtvcT8bLMJIfYaR/hPXZ9VTDKtWwSiWsEDbmCMOQRqNBNpllwB9gwB+mJ9lDtVGlUq9Qa9RIJVJkEhkyXoZ0Ik0qkSLpJnEdl3qjTr1Rp0GDrJfFi6cHax2wIC1ooFJnKZvMsrV3K1t7t571tkE9YDwYbwajqfIUh6YOsX9sPw8deohyWCbhJOhN95J0kxybO0Z0ylX8oD/I5sJm3jryVobzwxT9IjPVGaYqU5QqJXrTvWzo2cCG7AbGg3GePvo0Tx19ir0v7QVs4No1tIuslyUiIoxCpkvTrC+tJ+kmCeoBh48f5nDpMEE9wPd8TJ9h58BO+jJ9zVjSk+xh58BOdvTvIJ/KE0URU5Upjs4ebf6Mzo1Sa9TYOHgBm7a+icHsIL7nN08ShXQB3/NthVFEuVzix6UXmAwmKPZtY0NuI77n04gaTJYnGZ0dZTwYZ7I8yUR5gqlggtm5caaDCWarJ0gmMqTTBTKZdaQ9vzmiTjgJKmGFSmhPWL2p3vhkZlctOVE5Qala4sXEGGEYMs44Ja/EgD/AplyRTblNZBKZ5sms2ggI6gFBFFBJVEjmkqR7h8gkLqRBo3kCTTgJin6RAX+A/kw/hVSBfCpPLpkjn8pTSBea90tbRVFEUA+YLE8yU5thujrNbG2Walhtvh+qYZXRuVGOzR1jPBinETVwHZeEk6ARNag1as2fsBESRiFhI6QRNWjQIIqiBe+teqNuj6keUK6XqTfqRPsioiha8vWnch0Xz/Ga9c+3x8HBdVyyySxZL0vGyxBFUbOPymGZoB4suLial0vmKKQK5FI5gnrAd176DmHr/aTXkO/55FN5bh6+mZ3o1J/qIr7nM5IfWVB2PdcD9kRRrpfpSfY0RzzVsMrLMy/z8vTL9Gf62VLYQi6VO6t9vnv7u4miiCPTR9g3uo+njz7N/rH91Bo1Ek4CB4dKtcKBuQPUGjU812Pbum28Z/t7GM4Pc2T6CAcmDvD1579OMP+3aqcY9AcpVUtUwsqCcs/1msFvOZlEhnWZdYSNkLFg8T22fCpPUAuoR/VFz/meTy6ZI5fKkfWyhFGF8swRyqX/XXjFHYXNq3fP9ShVStSW+GKMn/AZ6hmi6BfZ0ruF8WCcJ378xKJ2eY6H7/n4cTC0IwAbCF3HbQbiWlhjqjK15Em49Rh8z8dzPFzXJYoijleOL+rL5eSTeYrZYjNAzQeIpJsk6SbxXA/P9WzA9hILRjytI+uEk2i2JeNlKE2WKBaLC17r4JB0k+RTeRtoUwWK2SKD/iD9mf5z/nvFKIqa/Zd0kyQTSTzHWzTyrzVqHJ05ykR5ojk6SibscTo4JNwEs7VZJoIJJsoTzNZmm/8XKTdFNawShDYYV8Nqc/RWb9Sb71UHh7n6HDPVGYJ6QDF19uuNvhY0UKmO4LneoiCUSqS4qPciLuq96FXV7TgOmwub2VzYzI3bF+cLO5N13VqvqB0cJsuTHJw8yHMTz/GjEz+iL91nR3I9G9jYs5GhniH6M/04OByvHOeV2VcYmxujHJaphlXK9TLT1WmOV44zVZ7CcRyGc8MM54fpz/QzHozbKdbZUXKpHEPZIQaz9l7fgD9AX6bv5GjsLEVRxHRtmvFgHBeXQtqOdJ6X55fsh2pYbQZxz/HO6oQcNkKmKlNMBBPM1GaYqc4smDqbrk4T1AM74olHC+vS6+jL9NGX7muOKHLJHMmEPZE6OHiux2B2cPkvCr1K7Vzrz3EcMp6dkjudpJtkpDDCSGFk2dcU/SIXFi48b23rhFxUoIFKqTMyf0U9b8AfYPcFu9l9we4Vt+3L9Nlpw+XXB24rx3EopAoUUoUzev3ZfimnVcK1039FvzOuzNXa1K58VEoppdQ50UCllFKqo2mgUkop1dE0UCmllOpoGqiUUkp1NA1USimlOpoGKqWUUh1NA5VSSqmO5kRL5QJ6HXvmmWfGgJdWux1KKbXGXLhr1671q7HjrgtUSiml1had+lNKKdXRNFAppZTqaBqolFJKdTQNVEoppTqaBiqllFIdTQOVUkqpjtY1iRONMS5wH/CTQAX4gIg8v7qtag9jTBK4H9gCpIE/Bp4DHgAi4H+A20Rk+ZzhryPGmEHgGeBqoE739sMfAb8IpLCfjcfosr6IPxsPYj8bIfAbdOF7whjzZuBeEbnKGHMxSxy/MeYu4Hps/3xIRJ5qV/u6aUR1A5ARkcuB24E/X+X2tNP7gAkR+TngWuCTwMeBO+MyB3jXKravbeIT06eBIC7q1n64CrgC2A28BRihO/viOsATkSuAu4E/ocv6wRjzh8DfA5m4aNHxG2N+Cvs+eTPwXuBT7WxjNwWqK4FHAUTkP4CfXt3mtNVXgY/G/3awV0S7sFfQAN8C3rYK7VoNfwb8LfBK/Lhb++HtwH8DXwO+ATxCd/bFIcCLZ1wKQI3u64fDwI0tj5c6/iuBvSISicj/YfusbatUdFOgKgCllsehMaYrpj5FZEZEpo0xeeAh4E7AEZH5ZUmmgd5Va2CbGGNuAsZE5NstxV3XD7Ei9mLtl4APAl8E3C7sixnstN9B4DPAJ+iy94SIPIwN0POWOv5Tz59t7ZduClQngHzLY1dE6qvVmHYzxowA/wZ8XkS+BLTOueeB46vSsPa6GbjaGPM94I3A54DBlue7pR8AJoBvi0hVRAQos/DE0y198XvYfrgEe//6Qew9u3nd0g+tljo3nHr+bGu/dFOgegI7H40x5mex0x5dwRgzBOwFPiIi98fFz8b3KQDeATy+Gm1rJxHZIyJvEZGrgB8CvwZ8q9v6IfZ94FpjjGOM2QT0AN/twr6Y4uRIYRJI0oWfjVMsdfxPAG83xrjGmM3YC/3xdjWoK6a+Yl/DXk0/ib1P8+ur3J52ugPoAz5qjJm/V/W7wCeMMSngAHZKsBt9GPhMt/WDiDxijNkDPIW9YL0NeJHu64u/AO43xjyOHUndAeyj+/qh1aLPhIiEcR/9gJPvl7bR1dOVUkp1tG6a+lNKKbUGaaBSSinV0TRQKaWU6mgaqJRSSnU0DVRKKaU6mgYqpZRSHU0DlVJKqY7WTX/wq5R6jRljbgU+BowCOWyaiF8WkepqtkutbTqiUmuOMeYqY0xkjHnvKeX/ZYx54DzUf5Mx5p5XW88S9V5rjLnlfNd7Pp2HY78UuENE3ghcArwBuOy8NE51LR1RqbXqIDYvzlcAjDGXYter61gi8uhqt6ENLsPmNgK4GLtc2aHVa456PdBApdaq/YAxxvSKSAmbHPKLwGZjTAF7slwHbMImeXOBK0XkV4wxDwL/KSL3nab+y40x38WmN/iYiHxzmXofwK7Cvgk4AuwRkU3GGP/Ucuw6cjuwQfY6IAtsw2ZWfWCpbURk03yDjDGXAP+AzSfmAr+KXVB1QZtE5G/ilCa/APjARuCvsAkA3wD8AXbtxxuwq2AXgbvjdA/z+0pi83Ztj/d1p4h8b6k2iMiRln77CeBz8fYXAO8UkROn6WelVqRTf2otexi40RjjAD8DPBmXXwx8RUSuAa4Bfl9EPgX48dRgaoUgBTCLTRh3PfDJOLHeonqBW4AXRWQ39t7MULz9cuXzekXkndhU8Lef4TZXYxeRfRtwFzYtx1JtmpcXkeuAe4HfxCbHu4WTCzL3xHVeA3z8lPxsHwDGRWQPNsDNZ3Rdqg1AM5XMMRG5TER2Ar/NyYSdSp0zDVRqLfsSdvpvDwtTMYwCNxhjvoBNEpmMy+8B3g/86RnU/f04m+kx7KhlYJl6dxIHSBE5CIzF2y9XPu+H8e8jnEwBvtI2n8XmAHoUGwTqpzlWgGfj38eBA3EyvKmW/T0mIg0RGY3LWzO2XgpcF+fuehib0bW4TBtat3mu5fF+Fub7UuqcaKBSa5aIvIAdFfwO8IWWpz4M/EBE3gd8FXDilAV/CdwK3Bc/Pp03ARhjNmC/vTa+VL3Yb7VdHr92G3YajdOUz1sqbcFK27wLeFxEfj7e/0eWadPp9tFqV7yvIewU57GW5w4CX45zd70jrntymTbMuwybFoJ4lPt+4F9WaINSK9JApda6fwRGRKT1hv03gNuMMY8BH8Je9d8LPCIif4cdDdxjjOk3xvzTMvX6xph/Bf4ZuDUejSxV7+eBLcaYf8dO15Xj7T+7TPnprLTNPuDuuF0fBP56qTYZY9JnsC+ADfF9uG8CvyUiYctznwZ2xPU+CbwkIo1l2jDvUuAmY8yz8esy6NSfOg80H5VSr4Ix5gogJyJ7jTHbgUdFZNty5edS12vU7puAHSJy+0qvVWq16bf+lHp1XgC+bIy5C3t/6LYVys+lLqW6mo6olFJKdTS9R6WUUqqjaaBSSinV0TRQKaWU6mgaqJRSSnU0DVRKKaU6mgYqpZRSHU0DlVJKqY72/6ky51ZvS4LZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_samples = 100\n",
    "MSE_vec4 = np.zeros(max_samples)\n",
    "for ind in range(1, max_samples + 1):\n",
    "    hit_tree4_loop = RandomForestRegressor(n_estimators=ind, max_features='sqrt',\n",
    "                                           bootstrap=True, oob_score=True,\n",
    "                                           random_state=15)\n",
    "    hit_tree4_loop.fit(X, y)\n",
    "    y_pred4_loop = hit_tree4_loop.oob_prediction_\n",
    "    MSE_vec4[ind - 1] = mean_squared_error(y, y_pred4_loop)\n",
    "    # print('MSE=', MSE_vec[ind - 1])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(np.arange(1, max_samples + 1), MSE_base * np.ones(max_samples),\n",
    "         label='Base MSE')\n",
    "plt.plot(np.arange(1, max_samples + 1), MSE_vec, label='Bagging MSE')\n",
    "plt.plot(np.arange(1, max_samples + 1), MSE_vec4, label='Random forest MSE')\n",
    "# for the minor ticks, use no labels; default NullFormatter\n",
    "plt.title('Basic vs. Bagging vs. Random Forest MSE', fontsize=20)\n",
    "plt.xlabel(r'Max. bagging samples $B$')\n",
    "plt.ylabel(r'MSE')\n",
    "plt.xlim((0, max_samples + 1))\n",
    "plt.legend(loc='best')\n",
    "\n",
    "print('Min. bag MSE=', MSE_vec.min(), ', Min. bag B=', np.argwhere(MSE_vec == MSE_vec.min())[0, 0] - 1)\n",
    "print('Min. rnd MSE=', MSE_vec4.min(), ', Min. rnd B=', np.argwhere(MSE_vec4 == MSE_vec4.min())[0, 0] - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Boosting\n",
    "\"Unlike fitting a single large decision tree to the data, which amounts to fitting the data hard and potentially overfitting, the boosting approach instead learns slowly. Given the current model, we fit a decision tree to the residuals from the model. That is, we fit a tree using the current residuals, rather than the outcome $Y$, as the response.\"\n",
    "\n",
    "\"By fitting small trees to the residuals, we slowly improve $\\hat{f}$ in areas where it does not perform well.\"\n",
    "\n",
    "The figure below is Figure 8.11 from James, et al (2013). This shows MSE performance of two boosting models versus a random forest on predicting cancer cells versus normal cells.\n",
    "\n",
    "![Figure8_11.png](images/Figure8_11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "* James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani, [*An Introduction to Statistical Learning with Applications in R*](http://link.springer.com.proxy.uchicago.edu/book/10.1007%2F978-1-4614-7138-7), New York, Springer (2013)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
