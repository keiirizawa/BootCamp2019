{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set #7 Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report, mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut, KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "import graphviz\n",
    "import pydotplus\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cultivar</th>\n",
       "      <th>alco</th>\n",
       "      <th>malic</th>\n",
       "      <th>ash</th>\n",
       "      <th>alk</th>\n",
       "      <th>magn</th>\n",
       "      <th>tot_phen</th>\n",
       "      <th>flav</th>\n",
       "      <th>nonfl_phen</th>\n",
       "      <th>proanth</th>\n",
       "      <th>color_int</th>\n",
       "      <th>hue</th>\n",
       "      <th>OD280rat</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.926136</td>\n",
       "      <td>13.006534</td>\n",
       "      <td>2.327159</td>\n",
       "      <td>2.367386</td>\n",
       "      <td>19.492045</td>\n",
       "      <td>99.840909</td>\n",
       "      <td>2.298920</td>\n",
       "      <td>2.043352</td>\n",
       "      <td>0.359545</td>\n",
       "      <td>1.597727</td>\n",
       "      <td>5.031761</td>\n",
       "      <td>0.961000</td>\n",
       "      <td>2.623409</td>\n",
       "      <td>748.477273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.771047</td>\n",
       "      <td>0.814431</td>\n",
       "      <td>1.117747</td>\n",
       "      <td>0.275617</td>\n",
       "      <td>3.355821</td>\n",
       "      <td>14.329499</td>\n",
       "      <td>0.627333</td>\n",
       "      <td>0.995579</td>\n",
       "      <td>0.123046</td>\n",
       "      <td>0.571958</td>\n",
       "      <td>2.317965</td>\n",
       "      <td>0.227225</td>\n",
       "      <td>0.705369</td>\n",
       "      <td>316.208737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.030000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>278.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.362500</td>\n",
       "      <td>1.597500</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>17.175000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.747500</td>\n",
       "      <td>1.242500</td>\n",
       "      <td>0.267500</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>1.990000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.050000</td>\n",
       "      <td>1.845000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.380000</td>\n",
       "      <td>2.155000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>4.640000</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>673.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.682500</td>\n",
       "      <td>3.047500</td>\n",
       "      <td>2.560000</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>107.250000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.882500</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>1.952500</td>\n",
       "      <td>6.147500</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>3.172500</td>\n",
       "      <td>986.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>14.830000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1680.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cultivar        alco       malic         ash         alk        magn  \\\n",
       "count  176.000000  176.000000  176.000000  176.000000  176.000000  176.000000   \n",
       "mean     1.926136   13.006534    2.327159    2.367386   19.492045   99.840909   \n",
       "std      0.771047    0.814431    1.117747    0.275617    3.355821   14.329499   \n",
       "min      1.000000   11.030000    0.740000    1.360000   10.600000   70.000000   \n",
       "25%      1.000000   12.362500    1.597500    2.210000   17.175000   88.000000   \n",
       "50%      2.000000   13.050000    1.845000    2.360000   19.500000   98.000000   \n",
       "75%      3.000000   13.682500    3.047500    2.560000   21.500000  107.250000   \n",
       "max      3.000000   14.830000    5.800000    3.230000   30.000000  162.000000   \n",
       "\n",
       "         tot_phen        flav  nonfl_phen     proanth   color_int         hue  \\\n",
       "count  176.000000  176.000000  176.000000  176.000000  176.000000  176.000000   \n",
       "mean     2.298920    2.043352    0.359545    1.597727    5.031761    0.961000   \n",
       "std      0.627333    0.995579    0.123046    0.571958    2.317965    0.227225   \n",
       "min      0.980000    0.340000    0.130000    0.410000    1.280000    0.480000   \n",
       "25%      1.747500    1.242500    0.267500    1.250000    3.200000    0.790000   \n",
       "50%      2.380000    2.155000    0.340000    1.560000    4.640000    0.975000   \n",
       "75%      2.800000    2.882500    0.430000    1.952500    6.147500    1.120000   \n",
       "max      3.880000    5.080000    0.660000    3.580000   13.000000    1.710000   \n",
       "\n",
       "         OD280rat      proline  \n",
       "count  176.000000   176.000000  \n",
       "mean     2.623409   748.477273  \n",
       "std      0.705369   316.208737  \n",
       "min      1.270000   278.000000  \n",
       "25%      1.990000   500.000000  \n",
       "50%      2.780000   673.500000  \n",
       "75%      3.172500   986.250000  \n",
       "max      4.000000  1680.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drink = pd.read_csv('data/strongdrink.txt')\n",
    "drink.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split dataset into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = drink[['alco', 'malic', 'tot_phen', 'color_int']].values\n",
    "y = drink['cultivar'].values\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size = 0.25, random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum likelihood estimation on Multinomial logistic regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coefficients and Intercepts for j=1 and j=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j = 1</th>\n",
       "      <th>j = 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>$\\beta_0$</th>\n",
       "      <td>-24.010571</td>\n",
       "      <td>22.802707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\beta_1$</th>\n",
       "      <td>1.700370</td>\n",
       "      <td>-1.468065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\beta_2$</th>\n",
       "      <td>-0.265602</td>\n",
       "      <td>-0.333055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\beta_3$</th>\n",
       "      <td>1.223892</td>\n",
       "      <td>0.664017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\beta_4$</th>\n",
       "      <td>0.022762</td>\n",
       "      <td>-0.922714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               j = 1      j = 2\n",
       "$\\beta_0$ -24.010571  22.802707\n",
       "$\\beta_1$   1.700370  -1.468065\n",
       "$\\beta_2$  -0.265602  -0.333055\n",
       "$\\beta_3$   1.223892   0.664017\n",
       "$\\beta_4$   0.022762  -0.922714"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mlogit = LogisticRegression(random_state=10, solver='newton-cg', multi_class='multinomial')\n",
    "Mlogit.fit(X_train, y_train)\n",
    "\n",
    "# Following lines of code motivated by:\n",
    "# https://stackoverflow.com/questions/30522724/take-multiple-lists-into-dataframe\n",
    "j1_list = np.append(Mlogit.intercept_[0],Mlogit.coef_[0])\n",
    "j2_list = np.append(Mlogit.intercept_[1],Mlogit.coef_[1])\n",
    "pd.DataFrame({\"j = 1\": j1_list,\n",
    "              \"j = 2\": j2_list},\n",
    "               index=[r\"$\\beta_0$\",r\"$\\beta_1$\",r\"$\\beta_2$\",r\"$\\beta_3$\",r\"$\\beta_4$\"],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = Mlogit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  0,  0],\n",
       "       [ 2, 19,  0],\n",
       "       [ 0,  0, 10]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      1.00      0.93        13\n",
      "           2       1.00      0.90      0.95        21\n",
      "           3       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           0.95        44\n",
      "   macro avg       0.96      0.97      0.96        44\n",
      "weighted avg       0.96      0.95      0.96        44\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = ['j=1', 'j=2', 'j=3']\n",
    "viz = ClassificationReport(LogisticRegression(random_state=0, solver='newton-cg', multi_class='multinomial'), classes=classes, support=True)\n",
    "viz.fit(X_train, y_train)\n",
    "viz.score(X_test, y_test)\n",
    "viz.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following definitions are based on:\n",
    "https://www.scikit-yb.org/en/latest/api/classifier/classification_report.html\n",
    "\n",
    "\n",
    "- Precision is \"the ability of classifier not to label an instance positive that is actually negative.\" Therefore, for all instances classified positive, about 86% was correct for j=1, 100% was correct for j=2, 100% was correct for j=3.\n",
    "\n",
    "- Recall is \"the ability of classifier to find all positive instances.\" Therefore, for all instances that were actually positive, 100% was classified correctly for j=1, about 90% was classified correctly for j=2, 100% was classified correctly for j=3.\n",
    "\n",
    "- F1 score is \"the weighted harmonic mean of precision and recall such that the best score is 1.0.\" The score illustrates the accuracy of classifier in classifying data points in that particular class compared to all other classes. Based on the f1 score, model seems to be best at predicting j=2. \n",
    "\n",
    "- Support is \"the number of actual occurences of class in the specified dataset.\" Therefore, we had the most data sets for j=2 classification.\n",
    "\n",
    "In conclusion, the model is best at predicting j=2 category (based on f1 score). This seems to be the class with the most observations (based on support). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j=1</th>\n",
       "      <th>j=2</th>\n",
       "      <th>j=3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>error rates</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              j=1  j=2  j=3\n",
       "error rates  0.13    0    0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"j=1\": 1 - 0.87,\n",
    "              \"j=2\": 1 - 1,\n",
    "              \"j=3\": 1 - 1},\n",
    "             index = ['error rates'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set MSE =  0.045454545454545456\n"
     ]
    }
   ],
   "source": [
    "print('Validation set MSE = ', mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 (b): Leave-one-out cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xvars = drink[['alco', 'malic', 'tot_phen', 'color_int']].values\n",
    "yvars = drink['cultivar'].values\n",
    "\n",
    "N_loo = Xvars.shape[0]\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(Xvars)\n",
    "MSE_vec = np.zeros(N_loo)\n",
    "y_test_vec = np.zeros(N_loo)\n",
    "y_pred_vec = np.zeros(N_loo)\n",
    "\n",
    "for train_index, test_index in loo.split(Xvars):\n",
    "    X_train, X_test = Xvars[train_index], Xvars[test_index]\n",
    "    y_train, y_test = yvars[train_index], yvars[test_index]\n",
    "    Mlogit = LogisticRegression(random_state=20, solver='newton-cg', multi_class='multinomial')\n",
    "    Mlogit.fit(X_train, y_train)\n",
    "    y_pred = Mlogit.predict(X_test)\n",
    "    \n",
    "    MSE_vec[test_index] = mean_squared_error(y_test, y_pred)\n",
    "    y_test_vec[test_index] = y_test\n",
    "    y_pred_vec[test_index] = y_pred\n",
    "    #print('MSE for test set', test_index, ' is', MSE_vec[test_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.90      0.93      0.92        59\n",
      "         2.0       0.91      0.90      0.91        71\n",
      "         3.0       0.96      0.93      0.95        46\n",
      "\n",
      "    accuracy                           0.92       176\n",
      "   macro avg       0.92      0.92      0.92       176\n",
      "weighted avg       0.92      0.92      0.92       176\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_vec, y_pred_vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j=1</th>\n",
       "      <th>j=2</th>\n",
       "      <th>j=3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>error rates</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             j=1   j=2   j=3\n",
       "error rates  0.1  0.09  0.04"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"j=1\": 1 - 0.9,\n",
    "              \"j=2\": 1 - 0.91,\n",
    "              \"j=3\": 1 - 0.96},\n",
    "             index = ['error rates'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to error rates from part (a), error rates in part (b) is higher for j=1 and lower for j=2 and j=3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test estimate MSE loocv= 0.09659090909090909\n",
      "test estimate MSE standard err= 0.39426250589387657\n"
     ]
    }
   ],
   "source": [
    "MSE_loo = MSE_vec.mean()\n",
    "MSE_loo_std = MSE_vec.std()\n",
    "print('test estimate MSE loocv=', MSE_loo)\n",
    "print('test estimate MSE standard err=', MSE_loo_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 (c): K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xvars = drink[['alco', 'malic', 'tot_phen', 'color_int']].values\n",
    "yvars = drink['cultivar'].values\n",
    "\n",
    "k = 4\n",
    "kf = KFold(n_splits=k, random_state=10, shuffle=True)\n",
    "kf.get_n_splits(Xvars)\n",
    "\n",
    "N_loo = Xvars.shape[0]\n",
    "MSE_vec_kf = np.zeros(k)\n",
    "y_test_vec = np.zeros(N_loo)\n",
    "y_pred_vec = np.zeros(N_loo)\n",
    "\n",
    "k_ind = int(0)\n",
    "for train_index, test_index in kf.split(Xvars):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    #print('k index=', k_ind)\n",
    "    X_train, X_test = Xvars[train_index], Xvars[test_index]\n",
    "    y_train, y_test = yvars[train_index], yvars[test_index]\n",
    "    Mlogit = LogisticRegression(random_state=0, solver='newton-cg', multi_class='multinomial')\n",
    "    Mlogit.fit(X_train, y_train)\n",
    "    y_pred = Mlogit.predict(X_test)\n",
    "\n",
    "    MSE_vec_kf[k_ind] = mean_squared_error(y_test, y_pred)\n",
    "    y_test_vec[test_index] = y_test\n",
    "    y_pred_vec[test_index] = y_pred\n",
    "    # print('MSE for test set', k_ind, ' is', MSE_vec_kf[k_ind])\n",
    "    k_ind += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.88      0.91       196\n",
      "         1.0       0.89      0.94      0.91       196\n",
      "\n",
      "    accuracy                           0.91       392\n",
      "   macro avg       0.91      0.91      0.91       392\n",
      "weighted avg       0.91      0.91      0.91       392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_vec, y_pred_vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j=1</th>\n",
       "      <th>j=2</th>\n",
       "      <th>j=3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>error rates</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              j=1   j=2   j=3\n",
       "error rates  0.13  0.09  0.04"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"j=1\": 1 - 0.87,\n",
    "              \"j=2\": 1 - 0.91,\n",
    "              \"j=3\": 1 - 0.96},\n",
    "             index = ['error rates'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to error rates from part (a) and (b), error rates in part (c) seems to be the max error rate between part (a) and part (b). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test estimate MSE k-fold= 0.10795454545454546\n",
      "test estimate MSE standard err= 0.07429941381035239\n"
     ]
    }
   ],
   "source": [
    "MSE_kf = MSE_vec_kf.mean()\n",
    "MSE_kf_std = MSE_vec_kf.std()\n",
    "print('test estimate MSE k-fold=', MSE_kf)\n",
    "print('test estimate MSE standard err=', MSE_kf_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with K of K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xvars = drink[['alco', 'malic', 'tot_phen', 'color_int']].values\n",
    "yvars = drink['cultivar'].values\n",
    "\n",
    "\n",
    "MSE_vec = np.zeros(drink.shape[0])\n",
    "for k in range(2, drink.shape[0]):\n",
    "    kf = KFold(n_splits=k, random_state=10, shuffle=True)\n",
    "    kf.get_n_splits(Xvars)\n",
    "\n",
    "    N_loo = Xvars.shape[0]\n",
    "    MSE_vec_kf = np.zeros(k)\n",
    "    y_test_vec = np.zeros(N_loo)\n",
    "    y_pred_vec = np.zeros(N_loo)\n",
    "\n",
    "    k_ind = int(0)\n",
    "    for train_index, test_index in kf.split(Xvars):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        #print('k index=', k_ind)\n",
    "        X_train, X_test = Xvars[train_index], Xvars[test_index]\n",
    "        y_train, y_test = yvars[train_index], yvars[test_index]\n",
    "        Mlogit = LogisticRegression(random_state=0, solver='newton-cg', multi_class='multinomial')\n",
    "        Mlogit.fit(X_train, y_train)\n",
    "        y_pred = Mlogit.predict(X_test)\n",
    "\n",
    "        MSE_vec_kf[k_ind] = mean_squared_error(y_test, y_pred)\n",
    "        y_test_vec[test_index] = y_test\n",
    "        y_pred_vec[test_index] = y_pred\n",
    "        # print('MSE for test set', k_ind, ' is', MSE_vec_kf[k_ind])\n",
    "        k_ind += 1\n",
    "        \n",
    "    MSE_kf = MSE_vec_kf.mean()\n",
    "    MSE_kf_std = MSE_vec_kf.std()\n",
    "    MSE_vec[k] = MSE_kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'MSE')"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "domain = np.linspace(2, drink.shape[0] - 1, drink.shape[0] - 2)\n",
    "plt.scatter(domain, MSE_vec[2:], s=5)\n",
    "plt.title(\"K in K-Fold vs MSE\")\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"MSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE is the sum of bias and variance. Therefore, in order to reduce MSE, we need to balance out bias and variance. Usually, bias and variance have an inverse relationship. In other words, high bias tend to cause low variance and vice versa. When we have small K, we expect low bias and high variance. Since we are using a lot of training data to construct our model, we get low bias. However, we have high variance when predicting y with our test data based on the model. This is because using a lot of training data to construct model could lead to over-fitting. In contrast, when we have a large K, we expect high variance and low variance. Since we are using small training data to contruct our model, we will have high bias. However, since we used only small training data to construct model, we expect less variance in predicting y from testing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biden</th>\n",
       "      <th>female</th>\n",
       "      <th>age</th>\n",
       "      <th>educ</th>\n",
       "      <th>dem</th>\n",
       "      <th>rep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1807.000000</td>\n",
       "      <td>1807.000000</td>\n",
       "      <td>1807.000000</td>\n",
       "      <td>1807.000000</td>\n",
       "      <td>1807.000000</td>\n",
       "      <td>1807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>62.163807</td>\n",
       "      <td>0.552850</td>\n",
       "      <td>47.535141</td>\n",
       "      <td>13.360266</td>\n",
       "      <td>0.431655</td>\n",
       "      <td>0.205313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>23.462034</td>\n",
       "      <td>0.497337</td>\n",
       "      <td>16.887444</td>\n",
       "      <td>2.440257</td>\n",
       "      <td>0.495444</td>\n",
       "      <td>0.404042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>85.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>59.500000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             biden       female          age         educ          dem  \\\n",
       "count  1807.000000  1807.000000  1807.000000  1807.000000  1807.000000   \n",
       "mean     62.163807     0.552850    47.535141    13.360266     0.431655   \n",
       "std      23.462034     0.497337    16.887444     2.440257     0.495444   \n",
       "min       0.000000     0.000000    18.000000     0.000000     0.000000   \n",
       "25%      50.000000     0.000000    34.000000    12.000000     0.000000   \n",
       "50%      60.000000     1.000000    47.000000    13.000000     0.000000   \n",
       "75%      85.000000     1.000000    59.500000    16.000000     1.000000   \n",
       "max     100.000000     1.000000    93.000000    17.000000     1.000000   \n",
       "\n",
       "               rep  \n",
       "count  1807.000000  \n",
       "mean      0.205313  \n",
       "std       0.404042  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden = pd.read_csv('data/biden.csv')\n",
    "biden.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = biden[['female', 'age', 'educ', 'dem', 'rep']].values\n",
    "y = biden['biden'].values\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size = 0.3, random_state=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=3, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=5,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_tree = DecisionTreeRegressor(max_depth=3, min_samples_leaf=5)\n",
    "biden_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"576pt\" height=\"261pt\"\n",
       " viewBox=\"0.00 0.00 576.00 261.37\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(.7007 .7007) rotate(0) translate(4 369)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-369 818,-369 818,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#f0b78f\" stroke=\"#000000\" d=\"M440.5,-365C440.5,-365 373.5,-365 373.5,-365 367.5,-365 361.5,-359 361.5,-353 361.5,-353 361.5,-309 361.5,-309 361.5,-303 367.5,-297 373.5,-297 373.5,-297 440.5,-297 440.5,-297 446.5,-297 452.5,-303 452.5,-309 452.5,-309 452.5,-353 452.5,-353 452.5,-359 446.5,-365 440.5,-365\"/>\n",
       "<text text-anchor=\"middle\" x=\"407\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">dem &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"407\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 556.262</text>\n",
       "<text text-anchor=\"middle\" x=\"407\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1264</text>\n",
       "<text text-anchor=\"middle\" x=\"407\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 62.165</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#f6d4bb\" stroke=\"#000000\" d=\"M334,-261C334,-261 272,-261 272,-261 266,-261 260,-255 260,-249 260,-249 260,-205 260,-205 260,-199 266,-193 272,-193 272,-193 334,-193 334,-193 340,-193 346,-199 346,-205 346,-205 346,-249 346,-249 346,-255 340,-261 334,-261\"/>\n",
       "<text text-anchor=\"middle\" x=\"303\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">rep &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"303\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 507.397</text>\n",
       "<text text-anchor=\"middle\" x=\"303\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 724</text>\n",
       "<text text-anchor=\"middle\" x=\"303\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 52.811</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M372.9465,-296.9465C363.7884,-287.7884 353.7838,-277.7838 344.2788,-268.2788\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"346.676,-265.7262 337.13,-261.13 341.7262,-270.676 346.676,-265.7262\"/>\n",
       "<text text-anchor=\"middle\" x=\"337.13\" y=\"-282.43\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<path fill=\"#e89253\" stroke=\"#000000\" d=\"M542,-261C542,-261 480,-261 480,-261 474,-261 468,-255 468,-249 468,-249 468,-205 468,-205 468,-199 474,-193 480,-193 480,-193 542,-193 542,-193 548,-193 554,-199 554,-205 554,-205 554,-249 554,-249 554,-255 548,-261 542,-261\"/>\n",
       "<text text-anchor=\"middle\" x=\"511\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">age &lt;= 54.5</text>\n",
       "<text text-anchor=\"middle\" x=\"511\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 347.197</text>\n",
       "<text text-anchor=\"middle\" x=\"511\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 540</text>\n",
       "<text text-anchor=\"middle\" x=\"511\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 74.706</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>0&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M441.0535,-296.9465C450.2116,-287.7884 460.2162,-277.7838 469.7212,-268.2788\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"472.2738,-270.676 476.87,-261.13 467.324,-265.7262 472.2738,-270.676\"/>\n",
       "<text text-anchor=\"middle\" x=\"476.87\" y=\"-282.43\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#f2c19e\" stroke=\"#000000\" d=\"M178,-157C178,-157 116,-157 116,-157 110,-157 104,-151 104,-145 104,-145 104,-101 104,-101 104,-95 110,-89 116,-89 116,-89 178,-89 178,-89 184,-89 190,-95 190,-101 190,-101 190,-145 190,-145 190,-151 184,-157 178,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"147\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">female &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"147\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 444.551</text>\n",
       "<text text-anchor=\"middle\" x=\"147\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 468</text>\n",
       "<text text-anchor=\"middle\" x=\"147\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 58.868</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M259.9594,-198.3062C240.9415,-185.6276 218.4275,-170.6184 198.5235,-157.349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"200.4327,-154.4153 190.1707,-151.7805 196.5498,-160.2397 200.4327,-154.4153\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<path fill=\"#fdf5ef\" stroke=\"#000000\" d=\"M334,-157C334,-157 272,-157 272,-157 266,-157 260,-151 260,-145 260,-145 260,-101 260,-101 260,-95 266,-89 272,-89 272,-89 334,-89 334,-89 340,-89 346,-95 346,-101 346,-101 346,-145 346,-145 346,-151 340,-157 334,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"303\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">female &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"303\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 432.623</text>\n",
       "<text text-anchor=\"middle\" x=\"303\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 256</text>\n",
       "<text text-anchor=\"middle\" x=\"303\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 41.738</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>1&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M303,-192.9465C303,-184.776 303,-175.9318 303,-167.3697\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"306.5001,-167.13 303,-157.13 299.5001,-167.13 306.5001,-167.13\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#f4c8a9\" stroke=\"#000000\" d=\"M74,-53C74,-53 12,-53 12,-53 6,-53 0,-47 0,-41 0,-41 0,-12 0,-12 0,-6 6,0 12,0 12,0 74,0 74,0 80,0 86,-6 86,-12 86,-12 86,-41 86,-41 86,-47 80,-53 74,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"43\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 470.335</text>\n",
       "<text text-anchor=\"middle\" x=\"43\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 235</text>\n",
       "<text text-anchor=\"middle\" x=\"43\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 56.489</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M110.3335,-88.9777C100.2675,-79.6376 89.3596,-69.5163 79.3135,-60.1947\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"81.5385,-57.4847 71.8274,-53.2485 76.7772,-62.616 81.5385,-57.4847\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#f1ba93\" stroke=\"#000000\" d=\"M178,-53C178,-53 116,-53 116,-53 110,-53 104,-47 104,-41 104,-41 104,-12 104,-12 104,-6 110,0 116,0 116,0 178,0 178,0 184,0 190,-6 190,-12 190,-12 190,-41 190,-41 190,-47 184,-53 178,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"147\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 407.088</text>\n",
       "<text text-anchor=\"middle\" x=\"147\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 233</text>\n",
       "<text text-anchor=\"middle\" x=\"147\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 61.266</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M147,-88.9777C147,-80.7364 147,-71.887 147,-63.5153\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"150.5001,-63.2484 147,-53.2485 143.5001,-63.2485 150.5001,-63.2484\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<path fill=\"#ffffff\" stroke=\"#000000\" d=\"M282,-53C282,-53 220,-53 220,-53 214,-53 208,-47 208,-41 208,-41 208,-12 208,-12 208,-6 214,0 220,0 220,0 282,0 282,0 288,0 294,-6 294,-12 294,-12 294,-41 294,-41 294,-47 288,-53 282,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"251\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 456.775</text>\n",
       "<text text-anchor=\"middle\" x=\"251\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 123</text>\n",
       "<text text-anchor=\"middle\" x=\"251\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 38.333</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M284.6667,-88.9777C279.9791,-80.2786 274.9264,-70.9018 270.1967,-62.1247\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"273.2386,-60.3914 265.4137,-53.2485 267.0763,-63.7121 273.2386,-60.3914\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<path fill=\"#fbebe0\" stroke=\"#000000\" d=\"M386,-53C386,-53 324,-53 324,-53 318,-53 312,-47 312,-41 312,-41 312,-12 312,-12 312,-6 318,0 324,0 324,0 386,0 386,0 392,0 398,-6 398,-12 398,-12 398,-41 398,-41 398,-47 392,-53 386,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"355\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 389.649</text>\n",
       "<text text-anchor=\"middle\" x=\"355\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 133</text>\n",
       "<text text-anchor=\"middle\" x=\"355\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 44.887</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>5&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M321.3333,-88.9777C326.0209,-80.2786 331.0736,-70.9018 335.8033,-62.1247\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"338.9237,-63.7121 340.5863,-53.2485 332.7614,-60.3914 338.9237,-63.7121\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<path fill=\"#ea985d\" stroke=\"#000000\" d=\"M542,-157C542,-157 480,-157 480,-157 474,-157 468,-151 468,-145 468,-145 468,-101 468,-101 468,-95 474,-89 480,-89 480,-89 542,-89 542,-89 548,-89 554,-95 554,-101 554,-101 554,-145 554,-145 554,-151 548,-157 542,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"511\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">educ &lt;= 15.5</text>\n",
       "<text text-anchor=\"middle\" x=\"511\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 345.027</text>\n",
       "<text text-anchor=\"middle\" x=\"511\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 340</text>\n",
       "<text text-anchor=\"middle\" x=\"511\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 72.606</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>8&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M511,-192.9465C511,-184.776 511,-175.9318 511,-167.3697\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"514.5001,-167.13 511,-157.13 507.5001,-167.13 514.5001,-167.13\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<path fill=\"#e68743\" stroke=\"#000000\" d=\"M698,-157C698,-157 636,-157 636,-157 630,-157 624,-151 624,-145 624,-145 624,-101 624,-101 624,-95 630,-89 636,-89 636,-89 698,-89 698,-89 704,-89 710,-95 710,-101 710,-101 710,-145 710,-145 710,-151 704,-157 698,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"667\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">female &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"667\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 330.649</text>\n",
       "<text text-anchor=\"middle\" x=\"667\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 200</text>\n",
       "<text text-anchor=\"middle\" x=\"667\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 78.275</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>8&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M554.0406,-198.3062C573.0585,-185.6276 595.5725,-170.6184 615.4765,-157.349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"617.4502,-160.2397 623.8293,-151.7805 613.5673,-154.4153 617.4502,-160.2397\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<path fill=\"#eb9d64\" stroke=\"#000000\" d=\"M490,-53C490,-53 428,-53 428,-53 422,-53 416,-47 416,-41 416,-41 416,-12 416,-12 416,-6 422,0 428,0 428,0 490,0 490,0 496,0 502,-6 502,-12 502,-12 502,-41 502,-41 502,-47 496,-53 490,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"459\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 369.301</text>\n",
       "<text text-anchor=\"middle\" x=\"459\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 247</text>\n",
       "<text text-anchor=\"middle\" x=\"459\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 71.105</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>9&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M492.6667,-88.9777C487.9791,-80.2786 482.9264,-70.9018 478.1967,-62.1247\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"481.2386,-60.3914 473.4137,-53.2485 475.0763,-63.7121 481.2386,-60.3914\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<path fill=\"#e78c4a\" stroke=\"#000000\" d=\"M594,-53C594,-53 532,-53 532,-53 526,-53 520,-47 520,-41 520,-41 520,-12 520,-12 520,-6 526,0 532,0 532,0 594,0 594,0 600,0 606,-6 606,-12 606,-12 606,-41 606,-41 606,-47 600,-53 594,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"563\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 258.693</text>\n",
       "<text text-anchor=\"middle\" x=\"563\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 93</text>\n",
       "<text text-anchor=\"middle\" x=\"563\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 76.591</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>9&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M529.3333,-88.9777C534.0209,-80.2786 539.0736,-70.9018 543.8033,-62.1247\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"546.9237,-63.7121 548.5863,-53.2485 540.7614,-60.3914 546.9237,-63.7121\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<path fill=\"#e89051\" stroke=\"#000000\" d=\"M698,-53C698,-53 636,-53 636,-53 630,-53 624,-47 624,-41 624,-41 624,-12 624,-12 624,-6 630,0 636,0 636,0 698,0 698,0 704,0 710,-6 710,-12 710,-12 710,-41 710,-41 710,-47 704,-53 698,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"667\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 399.015</text>\n",
       "<text text-anchor=\"middle\" x=\"667\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 79</text>\n",
       "<text text-anchor=\"middle\" x=\"667\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 75.19</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>12&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M667,-88.9777C667,-80.7364 667,-71.887 667,-63.5153\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"670.5001,-63.2484 667,-53.2485 663.5001,-63.2485 670.5001,-63.2484\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>14</title>\n",
       "<path fill=\"#e58139\" stroke=\"#000000\" d=\"M802,-53C802,-53 740,-53 740,-53 734,-53 728,-47 728,-41 728,-41 728,-12 728,-12 728,-6 734,0 740,0 740,0 802,0 802,0 808,0 814,-6 814,-12 814,-12 814,-41 814,-41 814,-47 808,-53 802,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"771\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 275.743</text>\n",
       "<text text-anchor=\"middle\" x=\"771\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 121</text>\n",
       "<text text-anchor=\"middle\" x=\"771\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 80.289</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>12&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M703.6665,-88.9777C713.7325,-79.6376 724.6404,-69.5163 734.6865,-60.1947\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"737.2228,-62.616 742.1726,-53.2485 732.4615,-57.4847 737.2228,-62.616\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1a1cd76550>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "import pydotplus\n",
    "\n",
    "biden_tree_viz = export_graphviz(\n",
    "    biden_tree,\n",
    "    out_file=None,\n",
    "    feature_names=['female', 'age', 'educ', 'dem', 'rep'],\n",
    "    class_names=['biden'],\n",
    "    rounded=True,\n",
    "    filled=True,\n",
    ")\n",
    "\n",
    "pydot_graph = pydotplus.graph_from_dot_data(biden_tree_viz)\n",
    "pydot_graph.write_png('biden_tree_viz')\n",
    "pydot_graph.set_size('\"8,8!\"')\n",
    "\n",
    "gvz_graph = graphviz.Source(pydot_graph.to_string())\n",
    "gvz_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the visualization, we see that female democrats who are older than 54.5 years of age have the biggest biden. In contrast, male republicans have the smallest biden. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE= 396.1937146321307\n"
     ]
    }
   ],
   "source": [
    "y_pred = biden_tree.predict(X_test)\n",
    "MSE1 = mean_squared_error(y_test, y_pred)\n",
    "print('MSE=', MSE1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandBestEstimator1= DecisionTreeRegressor(criterion='mse', max_depth=3, max_features=None,\n",
      "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=17,\n",
      "                      min_samples_split=14, min_weight_fraction_leaf=0.0,\n",
      "                      presort=False, random_state=None, splitter='best')\n",
      "RandBestParams1 (Optimal Tuning Parameter Values) = {'max_depth': 3, 'min_samples_leaf': 17, 'min_samples_split': 14}\n",
      "RandBestScore1 (MSE) = 401.6903602232667\n"
     ]
    }
   ],
   "source": [
    "# specify parameters and distributions to sample from\n",
    "param_dist1 = {'max_depth': [3, 10],\n",
    "               'min_samples_split': sp_randint(2, 20),\n",
    "               'min_samples_leaf': sp_randint(2, 20)}\n",
    "\n",
    "# Run randomized hyperparameter search\n",
    "random_search1 = \\\n",
    "    RandomizedSearchCV(biden_tree, param_distributions=param_dist1,\n",
    "                       n_iter=100, n_jobs=-1, cv=5, random_state=25,\n",
    "                       scoring='neg_mean_squared_error')\n",
    "\n",
    "random_search1.fit(X, y)  \n",
    "print('RandBestEstimator1=', random_search1.best_estimator_)\n",
    "print('RandBestParams1 (Optimal Tuning Parameter Values) =', random_search1.best_params_)\n",
    "print('RandBestScore1 (MSE) =', -random_search1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 (c): Random Forest Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandBestEstimator2 = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,\n",
      "                      max_features=2, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=17, min_samples_split=13,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                      n_jobs=None, oob_score=False, random_state=25, verbose=0,\n",
      "                      warm_start=False)\n",
      "RandBestParams2 (Optimal Tuning Parameter Values) = {'max_depth': 3, 'max_features': 2, 'min_samples_leaf': 17, 'min_samples_split': 13, 'n_estimators': 10}\n",
      "RandBestScore2 (MSE) = 397.0681090117028\n"
     ]
    }
   ],
   "source": [
    "param_dist2 = {'n_estimators': [10, 200],\n",
    "               'max_depth': [3, 10],\n",
    "               'min_samples_split': sp_randint(2, 20),\n",
    "               'min_samples_leaf': sp_randint(2, 20), \n",
    "               'max_features': sp_randint(1, 5)}\n",
    "\n",
    "biden_random_forest = RandomForestRegressor(random_state=25)\n",
    "\n",
    "random_search2 = RandomizedSearchCV(biden_random_forest, param_distributions=param_dist2,\n",
    "                       n_iter=100, n_jobs=-1, cv=5, random_state=25,\n",
    "                       scoring='neg_mean_squared_error')\n",
    "\n",
    "random_search2.fit(X, y)\n",
    "print('RandBestEstimator2 =', random_search2.best_estimator_)\n",
    "print('RandBestParams2 (Optimal Tuning Parameter Values) =', random_search2.best_params_)\n",
    "print('RandBestScore2 (MSE) =', -random_search2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>displ</th>\n",
       "      <th>hpwr</th>\n",
       "      <th>wgt</th>\n",
       "      <th>accl</th>\n",
       "      <th>yr</th>\n",
       "      <th>orgn</th>\n",
       "      <th>name</th>\n",
       "      <th>mpg_high</th>\n",
       "      <th>orgn1</th>\n",
       "      <th>orgn2</th>\n",
       "      <th>const</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cyl  displ   hpwr   wgt  accl  yr  orgn                       name  \\\n",
       "0  18.0    8  307.0  130.0  3504  12.0  70     1  chevrolet chevelle malibu   \n",
       "1  15.0    8  350.0  165.0  3693  11.5  70     1          buick skylark 320   \n",
       "2  18.0    8  318.0  150.0  3436  11.0  70     1         plymouth satellite   \n",
       "3  16.0    8  304.0  150.0  3433  12.0  70     1              amc rebel sst   \n",
       "4  17.0    8  302.0  140.0  3449  10.5  70     1                ford torino   \n",
       "\n",
       "   mpg_high  orgn1  orgn2  const  \n",
       "0         0      1      0      1  \n",
       "1         0      1      0      1  \n",
       "2         0      1      0      1  \n",
       "3         0      1      0      1  \n",
       "4         0      1      0      1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto = pd.read_csv('data/auto.csv', na_values='?')  # '?' exist for 'hpwr' column\n",
    "auto.columns = ['mpg', 'cyl', 'displ', 'hpwr', 'wgt', 'accl', 'yr', 'orgn','name']\n",
    "auto['mpg_high'] = (auto['mpg'] >= auto['mpg'].median()).astype('int')\n",
    "auto.dropna(inplace = True)\n",
    "auto[\"orgn1\"] = np.where(auto[\"orgn\"]==1,1,0)\n",
    "auto[\"orgn2\"] = np.where(auto[\"orgn\"]==2,1,0)\n",
    "auto['const'] = 1\n",
    "auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 392 entries, 0 to 396\n",
      "Data columns (total 13 columns):\n",
      "mpg         392 non-null float64\n",
      "cyl         392 non-null int64\n",
      "displ       392 non-null float64\n",
      "hpwr        392 non-null float64\n",
      "wgt         392 non-null int64\n",
      "accl        392 non-null float64\n",
      "yr          392 non-null int64\n",
      "orgn        392 non-null int64\n",
      "name        392 non-null object\n",
      "mpg_high    392 non-null int64\n",
      "orgn1       392 non-null int64\n",
      "orgn2       392 non-null int64\n",
      "const       392 non-null int64\n",
      "dtypes: float64(4), int64(8), object(1)\n",
      "memory usage: 42.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# have to make sure all relevant variables are the correct type:\n",
    "auto.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for test set 0  is 0.1326530612244898\n",
      "MSE for test set 1  is 0.08163265306122448\n",
      "MSE for test set 2  is 0.07142857142857142\n",
      "MSE for test set 3  is 0.07142857142857142\n"
     ]
    }
   ],
   "source": [
    "Xvars = auto[['const', 'cyl', 'displ', 'hpwr', 'wgt', 'accl', 'yr', 'orgn1', 'orgn2']].values\n",
    "yvars = auto['mpg_high'].values\n",
    "\n",
    "k = 4\n",
    "kf = KFold(n_splits=k, random_state=25, shuffle=True)\n",
    "kf.get_n_splits(Xvars)\n",
    "\n",
    "N_loo = Xvars.shape[0]\n",
    "MSE_vec_kf = np.zeros(k)\n",
    "y_test_vec = np.zeros(N_loo)\n",
    "y_pred_vec = np.zeros(N_loo)\n",
    "\n",
    "k_ind = int(0)\n",
    "for train_index, test_index in kf.split(Xvars):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    #print('k index=', k_ind)\n",
    "    X_train, X_test = Xvars[train_index], Xvars[test_index]\n",
    "    y_train, y_test = yvars[train_index], yvars[test_index]\n",
    "    LogReg = LogisticRegression(solver='newton-cg')\n",
    "    LogReg.fit(X_train, y_train)\n",
    "    y_pred = LogReg.predict(X_test)\n",
    "\n",
    "    MSE_vec_kf[k_ind] = mean_squared_error(y_test, y_pred)\n",
    "    y_test_vec[test_index] = y_test\n",
    "    y_pred_vec[test_index] = y_pred\n",
    "    print('MSE for test set', k_ind, ' is', MSE_vec_kf[k_ind])\n",
    "    k_ind += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.88      0.91       196\n",
      "         1.0       0.89      0.94      0.91       196\n",
      "\n",
      "    accuracy                           0.91       392\n",
      "   macro avg       0.91      0.91      0.91       392\n",
      "weighted avg       0.91      0.91      0.91       392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_vec, y_pred_vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg_high = 0</th>\n",
       "      <th>mpg_high = 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>error rates</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             mpg_high = 0  mpg_high = 1\n",
       "error rates          0.06          0.11"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"mpg_high = 0\": 1 - 0.94,\n",
    "              \"mpg_high = 1\": 1 - 0.89},\n",
    "             index = ['error rates'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test estimate MSE k-fold= 0.08928571428571427\n",
      "test estimate MSE standard err= 0.025382332579250516\n"
     ]
    }
   ],
   "source": [
    "MSE_kf = MSE_vec_kf.mean()\n",
    "MSE_kf_std = MSE_vec_kf.std()\n",
    "print('test estimate MSE k-fold=', MSE_kf)\n",
    "print('test estimate MSE standard err=', MSE_kf_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandBestEstimator3 = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=8,\n",
      "                      max_features=1, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=4, min_samples_split=4,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                      n_jobs=None, oob_score=False, random_state=25, verbose=0,\n",
      "                      warm_start=False)\n",
      "RandBestParams3 (Optimal Tuning Parameter Values) = {'max_depth': 8, 'max_features': 1, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 10}\n",
      "RandBestScore3 (MSE) = 0.0932354521565113\n"
     ]
    }
   ],
   "source": [
    "# Random Forest already have constant term ???\n",
    "X = auto[['cyl', 'displ', 'hpwr', 'wgt', 'accl', 'yr', 'orgn1', 'orgn2']].values\n",
    "y = auto['mpg_high'].values\n",
    "\n",
    "param_dist3 = {'n_estimators': [10, 200],\n",
    "               'max_depth': [3, 8],\n",
    "               'min_samples_split': sp_randint(2, 20),\n",
    "               'min_samples_leaf': sp_randint(2, 20), \n",
    "               'max_features': sp_randint(1, 8)}\n",
    "\n",
    "auto_random_forest = RandomForestRegressor(random_state=25)\n",
    "\n",
    "random_search3 = RandomizedSearchCV(auto_random_forest, param_distributions=param_dist3,\n",
    "                       n_iter=100, n_jobs=-1, cv=4, random_state=25,\n",
    "                       scoring='neg_mean_squared_error')\n",
    "\n",
    "random_search3.fit(X, y)\n",
    "print('RandBestEstimator3 =', random_search3.best_estimator_)\n",
    "print('RandBestParams3 (Optimal Tuning Parameter Values) =', random_search3.best_params_)\n",
    "print('RandBestScore3 (MSE) =', -random_search3.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandBestEstimator4 = SVC(C=1.8094629152568114, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=False,\n",
      "    tol=0.001, verbose=False)\n",
      "RandBestParams4 (Optimal Tuning Parameter Values) = {'C': 1.8094629152568114, 'gamma': 'scale', 'shrinking': False}\n",
      "RandBestScore4 (MSE) = 0.11989795918367346\n"
     ]
    }
   ],
   "source": [
    "param_dist4 = {'C': sp_uniform(loc=0.2, scale=4.0),\n",
    "               'gamma': ['scale', 'auto'],\n",
    "               'shrinking': [True, False]}\n",
    "\n",
    "svc = svm.SVC(kernel='rbf')\n",
    "\n",
    "random_search4 = RandomizedSearchCV(svc, param_distributions=param_dist4,\n",
    "                                    n_iter=100, n_jobs=-1, cv=4, random_state=25,\n",
    "                                    scoring='neg_mean_squared_error')\n",
    "\n",
    "random_search4.fit(X, y)\n",
    "print('RandBestEstimator4 =', random_search4.best_estimator_)\n",
    "print('RandBestParams4 (Optimal Tuning Parameter Values) =', random_search4.best_params_)\n",
    "print('RandBestScore4 (MSE) =', -random_search4.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the MSE, the best predictor of mpg_high is the Random Forest Classifier because it has the lowest MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cultivar</th>\n",
       "      <th>alco</th>\n",
       "      <th>malic</th>\n",
       "      <th>ash</th>\n",
       "      <th>alk</th>\n",
       "      <th>magn</th>\n",
       "      <th>tot_phen</th>\n",
       "      <th>flav</th>\n",
       "      <th>nonfl_phen</th>\n",
       "      <th>proanth</th>\n",
       "      <th>color_int</th>\n",
       "      <th>hue</th>\n",
       "      <th>OD280rat</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.926136</td>\n",
       "      <td>13.006534</td>\n",
       "      <td>2.327159</td>\n",
       "      <td>2.367386</td>\n",
       "      <td>19.492045</td>\n",
       "      <td>99.840909</td>\n",
       "      <td>2.298920</td>\n",
       "      <td>2.043352</td>\n",
       "      <td>0.359545</td>\n",
       "      <td>1.597727</td>\n",
       "      <td>5.031761</td>\n",
       "      <td>0.961000</td>\n",
       "      <td>2.623409</td>\n",
       "      <td>748.477273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.771047</td>\n",
       "      <td>0.814431</td>\n",
       "      <td>1.117747</td>\n",
       "      <td>0.275617</td>\n",
       "      <td>3.355821</td>\n",
       "      <td>14.329499</td>\n",
       "      <td>0.627333</td>\n",
       "      <td>0.995579</td>\n",
       "      <td>0.123046</td>\n",
       "      <td>0.571958</td>\n",
       "      <td>2.317965</td>\n",
       "      <td>0.227225</td>\n",
       "      <td>0.705369</td>\n",
       "      <td>316.208737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.030000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>278.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.362500</td>\n",
       "      <td>1.597500</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>17.175000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.747500</td>\n",
       "      <td>1.242500</td>\n",
       "      <td>0.267500</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>1.990000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.050000</td>\n",
       "      <td>1.845000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.380000</td>\n",
       "      <td>2.155000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>4.640000</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>673.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.682500</td>\n",
       "      <td>3.047500</td>\n",
       "      <td>2.560000</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>107.250000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.882500</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>1.952500</td>\n",
       "      <td>6.147500</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>3.172500</td>\n",
       "      <td>986.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>14.830000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1680.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cultivar        alco       malic         ash         alk        magn  \\\n",
       "count  176.000000  176.000000  176.000000  176.000000  176.000000  176.000000   \n",
       "mean     1.926136   13.006534    2.327159    2.367386   19.492045   99.840909   \n",
       "std      0.771047    0.814431    1.117747    0.275617    3.355821   14.329499   \n",
       "min      1.000000   11.030000    0.740000    1.360000   10.600000   70.000000   \n",
       "25%      1.000000   12.362500    1.597500    2.210000   17.175000   88.000000   \n",
       "50%      2.000000   13.050000    1.845000    2.360000   19.500000   98.000000   \n",
       "75%      3.000000   13.682500    3.047500    2.560000   21.500000  107.250000   \n",
       "max      3.000000   14.830000    5.800000    3.230000   30.000000  162.000000   \n",
       "\n",
       "         tot_phen        flav  nonfl_phen     proanth   color_int         hue  \\\n",
       "count  176.000000  176.000000  176.000000  176.000000  176.000000  176.000000   \n",
       "mean     2.298920    2.043352    0.359545    1.597727    5.031761    0.961000   \n",
       "std      0.627333    0.995579    0.123046    0.571958    2.317965    0.227225   \n",
       "min      0.980000    0.340000    0.130000    0.410000    1.280000    0.480000   \n",
       "25%      1.747500    1.242500    0.267500    1.250000    3.200000    0.790000   \n",
       "50%      2.380000    2.155000    0.340000    1.560000    4.640000    0.975000   \n",
       "75%      2.800000    2.882500    0.430000    1.952500    6.147500    1.120000   \n",
       "max      3.880000    5.080000    0.660000    3.580000   13.000000    1.710000   \n",
       "\n",
       "         OD280rat      proline  \n",
       "count  176.000000   176.000000  \n",
       "mean     2.623409   748.477273  \n",
       "std      0.705369   316.208737  \n",
       "min      1.270000   278.000000  \n",
       "25%      1.990000   500.000000  \n",
       "50%      2.780000   673.500000  \n",
       "75%      3.172500   986.250000  \n",
       "max      4.000000  1680.000000  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drink = pd.read_csv('data/strongdrink.txt', na_values='?') \n",
    "drink.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in [1,2,3]:\n",
    "    df = drink[drink['cultivar']==i]\n",
    "    plt.scatter(df['alco'], df['color_int'], s=20, label='cultivar type = {}'.format(i))\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Alcohol\")\n",
    "plt.ylabel(\"Color Intensity\")\n",
    "plt.title(\"Alcohol vs Color Intensity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = drink[['alco', 'malic', 'tot_phen', 'color_int']].values\n",
    "y = drink['cultivar'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandBestEstimator1 = LogisticRegression(C=2.665871587495725, class_weight=None, dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=25, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "RandBestParams1 (Optimal Tuning Parameter Values) = {'C': 2.665871587495725, 'penalty': 'l1'}\n",
      "RandBestScore1 (MSE) = 0.11931818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "param_dist1 = {'penalty': ['l1', 'l2'], \n",
    "               'C': sp_uniform(0.1, 10.0)}\n",
    "\n",
    "Mlogit = LogisticRegression(random_state=25)\n",
    "\n",
    "random_search1 = RandomizedSearchCV(Mlogit, param_dist1, \n",
    "                                    n_iter=200, n_jobs=-1, cv=5, \n",
    "                                    random_state=25, scoring='neg_mean_squared_error')\n",
    "\n",
    "random_search1.fit(X, y)\n",
    "print('RandBestEstimator1 =', random_search1.best_estimator_)\n",
    "print('RandBestParams1 (Optimal Tuning Parameter Values) =', random_search1.best_params_)\n",
    "print('RandBestScore1 (MSE) =', -random_search1.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandBestEstimator2 = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=2, max_features=1, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=7,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=25, verbose=0,\n",
      "                       warm_start=False)\n",
      "RandBestParams2 (Optimal Tuning Parameter Values) = {'max_depth': 2, 'max_features': 1, 'min_samples_leaf': 2, 'min_samples_split': 7, 'n_estimators': 200}\n",
      "RandBestScore2 (MSE) = 0.14772727272727273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "param_dist2 = {'n_estimators': [10, 200],\n",
    "               'max_depth': [2, 4],\n",
    "               'min_samples_split': sp_randint(2, 20),\n",
    "               'min_samples_leaf': sp_randint(2, 20),\n",
    "               'max_features': sp_randint(1, 4)}\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=25)\n",
    "\n",
    "random_search2 = RandomizedSearchCV(random_forest, param_distributions=param_dist2,\n",
    "                       n_iter=200, n_jobs=-1, cv=5, random_state=25,\n",
    "                       scoring='neg_mean_squared_error')\n",
    "\n",
    "random_search2.fit(X, y)\n",
    "print('RandBestEstimator2 =', random_search2.best_estimator_)\n",
    "print('RandBestParams2 (Optimal Tuning Parameter Values) =', random_search2.best_params_)\n",
    "print('RandBestScore2 (MSE) =', -random_search2.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandBestEstimator3 = SVC(C=9.58835943424229, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "RandBestParams3 (Optimal Tuning Parameter Values) = {'C': 9.58835943424229, 'gamma': 'scale', 'shrinking': True}\n",
      "RandBestScore3 (MSE) = 0.13636363636363635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "param_dist3 = {'C': sp_uniform(loc=0.1, scale=10.0),\n",
    "               'gamma': ['scale', 'auto'],\n",
    "               'shrinking': [True, False]}\n",
    "\n",
    "svc = svm.SVC(kernel='rbf')\n",
    "\n",
    "random_search3 = RandomizedSearchCV(svc, param_distributions=param_dist3,\n",
    "                                    n_iter=200, n_jobs=-1, cv=5, random_state=25,\n",
    "                                    scoring='neg_mean_squared_error')\n",
    "\n",
    "random_search3.fit(X, y)\n",
    "print('RandBestEstimator3 =', random_search3.best_estimator_)\n",
    "print('RandBestParams3 (Optimal Tuning Parameter Values) =', random_search3.best_params_)\n",
    "print('RandBestScore3 (MSE) =', -random_search3.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandBestEstimator4 = MLPClassifier(activation='relu', alpha=2.158912119744818, batch_size='auto',\n",
      "              beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=68, learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=25, shuffle=True, solver='adam', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "RandBestParams4 (Optimal Tuning Parameter Values) = {'activation': 'relu', 'alpha': 2.158912119744818, 'hidden_layer_sizes': 68}\n",
      "RandBestScore4 (MSE) = 0.19318181818181818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(random_state=25)\n",
    "\n",
    "param_dist4 = {'hidden_layer_sizes': sp_randint(1, 100),\n",
    "               'activation': ['logistic', 'relu'],\n",
    "               'alpha': sp_uniform(0.1, 10.0)}\n",
    "\n",
    "random_search4 = RandomizedSearchCV(mlp, param_distributions=param_dist4,\n",
    "                                    n_iter=200, n_jobs=-1, cv=5, random_state=25, \n",
    "                                    scoring='neg_mean_squared_error')\n",
    "\n",
    "random_search4.fit(X, y)\n",
    "print('RandBestEstimator4 =', random_search4.best_estimator_)\n",
    "print('RandBestParams4 (Optimal Tuning Parameter Values) =', random_search4.best_params_)\n",
    "print('RandBestScore4 (MSE) =', -random_search4.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 (f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the MSE, the best predictor of cultivar is the multinomial logistic regression because it has the lowest MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
